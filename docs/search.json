[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simon's Public NAO Notebook",
    "section": "",
    "text": "Testing single-read versions of RAW and CLEAN\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying promising MBTA stations for swab sampling: MBTA Ridership\n\n\nHow many passengers use different MBTA stations?\n\n\n\nMBTA\n\n\nSwab sampling\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html",
    "href": "posts/2024-07-25-mbta-ridership/index.html",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "",
    "text": "As part of our swab sampling pilot project, we want to identify stations where we can collect a lot of swab samples in a short amount of time. One way to identify these stations is to look at the number of passengers that enter each station, which the MBTA provides. They give the number of passengers that enter a gated station every 30 minutes. Crucially, this doesn’t tell us how many people leave the station, which would be useful to understand full passenger volume of a station."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#red-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#red-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Red line",
    "text": "Red line\nThe red line is closest to the office and MIT and thus the obvious candidate for sampling. Let’s take a look at the daily ridership, averaged over the month of June 2024, for the red line stations closest to the SecureBio office (Porter, Central, Kendall/MIT, Charles/MGH, Park Street, and Downtown Crossing).\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Porter\", \"Harvard\", \"Central\", \"Kendall/MIT\", \"Charles/MGH\", \"Park Street\", \"Downtown Crossing\"]\n\n\nridership_2024[\"date_dt\"] = pd.to_datetime(ridership_2024[\"service_date\"])\nreference_date = pd.to_datetime(\"1800-06-01\")  # reference date is used as a placeholder, set to an implausible value\nridership_2024[\"time_dt\"] = pd.to_datetime(reference_date.strftime('%Y-%m-%d') + ' ' + ridership_2024[\"time_period\"].str.strip(\"()\"))\nmorning_peak_rides = {}\nevening_peak_rides = {}\n\n# Data represents ridership over the half hour starting at the given time. Adding 15 minutes to create correct center of interval.\nridership_2024[\"time_dt\"] = ridership_2024[\"time_dt\"] + pd.Timedelta(minutes=15)\n\n\nred_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Red Line\"]\njune_2024 = red_line_2024[red_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership_morning = mean_use_per_interval[mean_use_per_interval[\"time_dt\"].dt.hour.between(1, 10)][\"gated_entries\"].max()\n        max_usership_evening = mean_use_per_interval[mean_use_per_interval[\"time_dt\"].dt.hour.between(16, 23)][\"gated_entries\"].max()\n        morning_peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership_morning]\n        evening_peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership_evening]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(station)\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Red Line stations in June 2024\")\nplt.show()\n\n# Morning peaks:\n\nmorning_peak_ride_porter = round(morning_peak_rides[\"Porter\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_porter = morning_peak_rides[\"Porter\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_central = round(morning_peak_rides[\"Central\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_central = morning_peak_rides[\"Central\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_kendall = round(morning_peak_rides[\"Kendall/MIT\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_kendall = morning_peak_rides[\"Kendall/MIT\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_harvard = round(morning_peak_rides[\"Harvard\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_harvard = morning_peak_rides[\"Harvard\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\nevening_peak_ride_kendall = round(evening_peak_rides[\"Kendall/MIT\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_kendall = evening_peak_rides[\"Kendall/MIT\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nevening_peak_ride_harvard = round(evening_peak_rides[\"Harvard\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_harvard = evening_peak_rides[\"Harvard\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nevening_peak_ride_charles = round(evening_peak_rides[\"Charles/MGH\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_charles = evening_peak_rides[\"Charles/MGH\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nCentral, Harvard, and Porter stations see the most ppl entering stations in the morning due to commuters going into the city (304, 275, and 243 from 8:30-9:00, respectively). Kendall/MIT, Charles/MGH, and Harvard see the most people entering in the evening (618, 345, and 482 from 17:00-17:30, respectively). People who take the T from a commuter station in the evening likely arrived at the same station in the evening. We can thus assume that the evening bump in ridership for Kendall and Harvard can be added to the morning bump.\nBased on the data here, Kendall and Harvard station all seem like good stations to do sampling in the morning."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#green-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#green-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Green line",
    "text": "Green line\nThe green line is fairly close to the office (two stations away). Looking at Figure 2, the four Green line stations closest to the nearest Red line station are Government Center, Haymarket, Boylston, and Copley.\n\n\n\n\n\n\nFigure 2: MBTA Subway Map (2013)\n\n\n\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Government Center\", \"Haymarket\", \"Boylston\", \"Copley\"]\npeak_rides = {}\n\n\ngreen_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Green Line\"]\njune_2024 = green_line_2024[green_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n        peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(f\"{station} is more than three stations away from Kendall close to Kendall\")\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\n\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Green Line stations in June 2024\")\nplt.show()\n\npeak_ride_copley = round(peak_rides[\"Copley\"][\"gated_entries\"].values[0])\npeak_ride_time_copley = peak_rides[\"Copley\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_haymarket = round(peak_rides[\"Haymarket\"][\"gated_entries\"].values[0])\npeak_ride_time_haymarket = peak_rides[\"Haymarket\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\nCopley and Government Center see the most ridership (466) and 118 at 17:15, respectively at from 17:00 to 17:30. Again, the same pattern is visible where many people enter stations in the evening, and thus likely leave the station in the evening."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#orange-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#orange-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Orange line",
    "text": "Orange line\nFinally, let’s look at the Orange line. The Orange line is the furthest away from the office, but it is still only 3 stations away. Let’s again look at the four Orange line stations closest to the office. Additionally I include Back Bay station as that station has a fairly big entrance hall which could be suitable for sampling:\n\n\n\nBack Bay Station\n\n\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Tufts Medical Center\", \"Haymarket\", \"Chinatown\", \"State Street\", \"Back Bay\"]\npeak_rides = {}\n\norange_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Orange Line\"]\njune_2024 = orange_line_2024[orange_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n        peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(station)\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Orange Line stations in June 2024\")\nplt.show()\n\npeak_ride_back_bay = round(peak_rides[\"Back Bay\"][\"gated_entries\"].values[0])\npeak_ride_time_back_bay = peak_rides[\"Back Bay\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_state_street = round(peak_rides[\"State Street\"][\"gated_entries\"].values[0])\npeak_ride_time_state_street = peak_rides[\"State Street\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\nHere Back Bay and State Street look great, with a peak ridership of 432 and 490 from 17:00 to 17:30."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#north-and-south-station",
    "href": "posts/2024-07-25-mbta-ridership/index.html#north-and-south-station",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "North and South Station",
    "text": "North and South Station\nFinally, let’s look at North Station and South Station. Given that they are connected to the Amtrak network, they might see a lot of traffic. Additionaly we are currently in conversation with the administrators of both stations to do sampling there (though sampling would probaly take place in the train station, not in the subway station).\n\n\nCode\ntarget_stations = [\"North Station\", \"South Station\"]\nplt.figure(figsize=(12, 4), dpi=600)\n\npeak_rides = {}\n\njune_ridership = ridership_2024[ridership_2024[\"date_dt\"].dt.month == 6]\n\nfor station in target_stations:\n    station_ridership = june_ridership[june_ridership[\"station_name\"] == station]\n    lines_in_station = station_ridership[\"route_or_line\"].unique()\n    for line in lines_in_station:\n        line_ridership = station_ridership[station_ridership[\"route_or_line\"] == line]\n        mean_use_per_interval = line_ridership.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n\n        peak_rides[(station, line)] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n\n        line_to_sns_color_dict = {\"Green Line\": \"#58ac6c\", \"Orange Line\": \"#f79646\", \"Red Line\": \"#d62728\", \"Silver Line\": \"#647c9a\"}\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=f\"{station} ({line})\", color=line_to_sns_color_dict[line])\n\nax = plt.gca()\nplt.legend()\n\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval at North and South Stations in June 2024\")\n\npeak_ride_north_green = round(peak_rides[\"North Station\", \"Green Line\"][\"gated_entries\"].values[0])\npeak_ride_time_north_green = peak_rides[\"North Station\", \"Green Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_north_orange = round(peak_rides[\"North Station\", \"Orange Line\"][\"gated_entries\"].values[0])\npeak_ride_time_north_orange = peak_rides[\"North Station\", \"Orange Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_south_red = round(peak_rides[\"South Station\", \"Red Line\"][\"gated_entries\"].values[0])\npeak_ride_time_south_red = peak_rides[\"South Station\", \"Red Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_south_silver = round(peak_rides[\"South Station\", \"Silver Line\"][\"gated_entries\"].values[0])\npeak_ride_time_south_silver = peak_rides[\"South Station\", \"Silver Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nFor both stations and lines, peak traffic is again at 17:00 to 17:30, with 156 and 304 riders at North Station’s Green and Orange line, and 498 and 213 riders at South Station’s Red and Silver line, respectively."
  },
  {
    "objectID": "posts/2024-10-24-mgs-single-read-eval/index.html",
    "href": "posts/2024-10-24-mgs-single-read-eval/index.html",
    "title": "Testing single-read versions of RAW and CLEAN",
    "section": "",
    "text": "I’m adapting mgs-workflow to take in single-read sequencing data. Here I’m checking if: i) the output of the single-read RAW and CLEAN workflows look as expected, and ii) ifthe output of the paired-end version is the same as the output of the test run on dev.\nI find that the single-read QC output of the RAW and CLEAN workflows looks as expected, i.e., similar to those of the forward reads in the paired-end run. Differences in the two datasets are mostly mediated by the reverse reads of the paired-end run being low quality, leading to fewer reads and base pairs passing through fastp, and thus affecting the paired-end QC measures. This suggests we should possibly use a different test dataset going forward.\nI will amend the PROFILE workflow of mgs-workflow next.\n\nIntroduction\nThe single-end dataset simply consists of the forward reads of our usual test dataset. Additionally, I work with the paired-end test dataset, run on the single-read-raw pipeline with read_type == paired_end, and the same dataset run with the dev branch of mgs-workflow.\nI compared the qc output of the two paired-end runs, and they are identical, suggesting that the addition of single-read functionality doesn’t impede mgs-workflow runs on paired-end data.\n\n\nCode\nsingle_read_dir = \"mgs-results/test_single_read\"\npaired_read_dir = \"mgs-results/test_paired_end\"\ntest_dir = \"mgs-results/test\"\nfull_test_dir = \"mgs-results/test-full\"\n\nse_output_dir = os.path.join(single_read_dir, \"output\")\npe_output_dir = os.path.join(paired_read_dir, \"output\")\ntest_output_dir = os.path.join(test_dir, \"output\")\nfull_test_output_dir = os.path.join(full_test_dir, \"output\")\n\nse_results_dir = os.path.join(se_output_dir, \"results\")\npe_results_dir = os.path.join(pe_output_dir, \"results\")\ntest_results_dir = os.path.join(test_output_dir, \"results\")\nfull_test_results_dir = os.path.join(full_test_output_dir, \"results\")\n\nse_qc_dir = os.path.join(se_results_dir, \"qc\")\npe_qc_dir = os.path.join(pe_results_dir, \"qc\")\ntest_qc_dir = os.path.join(test_results_dir, \"qc\")\nfull_test_qc_dir = os.path.join(full_test_results_dir, \"qc\")\n\nse_basic_stats_path = os.path.join(se_qc_dir, \"qc_basic_stats.tsv.gz\")\nse_adapter_stats_path = os.path.join(se_qc_dir, \"qc_adapter_stats.tsv.gz\")\nse_quality_base_stats_path = os.path.join(se_qc_dir, \"qc_quality_base_stats.tsv.gz\")\nse_quality_seq_stats_path = os.path.join(se_qc_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\n\n\npe_basic_stats_path = os.path.join(pe_qc_dir, \"qc_basic_stats.tsv.gz\")\npe_adapter_stats_path = os.path.join(pe_qc_dir, \"qc_adapter_stats.tsv.gz\")\npe_quality_base_stats_path = os.path.join(pe_qc_dir, \"qc_quality_base_stats.tsv.gz\")\npe_quality_seq_stats_path = os.path.join(pe_qc_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\n\ntest_basic_stats_path = os.path.join(test_qc_dir, \"qc_basic_stats.tsv.gz\")\ntest_adapter_stats_path = os.path.join(test_qc_dir, \"qc_adapter_stats.tsv.gz\")\ntest_quality_base_stats_path = os.path.join(test_qc_dir, \"qc_quality_base_stats.tsv.gz\")\ntest_quality_seq_stats_path = os.path.join(test_qc_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\nfull_test_basic_stats_path = os.path.join(full_test_qc_dir, \"qc_basic_stats.tsv.gz\")\nfull_test_adapter_stats_path = os.path.join(full_test_qc_dir, \"qc_adapter_stats.tsv.gz\")\nfull_test_quality_base_stats_path = os.path.join(full_test_qc_dir, \"qc_quality_base_stats.tsv.gz\")\nfull_test_quality_seq_stats_path = os.path.join(full_test_qc_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\n\n\n\nAssessing basic stats for both raw and cleaned reads\n\n\nCode\nse_basic_stats = pd.read_csv(se_basic_stats_path, sep='\\t')\npe_basic_stats = pd.read_csv(pe_basic_stats_path, sep='\\t')\ntest_basic_stats = pd.read_csv(test_basic_stats_path, sep='\\t')\nfull_test_basic_stats = pd.read_csv(full_test_basic_stats_path, sep='\\t')\n\n\nComparing the basic stats of the single-read version to the paired-end version, the most notable difference is paired-end data losing more bases and reads through FASTP cleaning. Accounting for paired-end reads containing twice as many base pairs, cleaned paired-end read files contain 16.4% fewer bases than cleaned single-end read files. This is largely due to FASTP dropping low-quality read pairs, with the number of cleaned paired-end reads 18.5% lower than the number of cleaned single-end reads. See Table 2.1 and Table 2.2 for per-sample statistics.\nMy current hypothesis for this pattern is that the reverse reads are very low quality, as seen in Figure 4.1, leading FASTP to drop many of the read pairs with a low-quality reverse read. I won’t investigate this further for now, but it suggests we should use a new test dataset that has high-quality forward and reverse reads.\n\n\nCode\ncombined_df = se_basic_stats[[\"sample\", \"n_bases_approx\", \"stage\", \"n_read_pairs\"]].merge(\n    pe_basic_stats[[\"sample\", \"n_bases_approx\", \"stage\", \"n_read_pairs\"]],\n    on=[\"sample\", \"stage\"],\n    suffixes=[\"_single\", \"_paired\"]\n)\n\ncombined_df[\"ratio_bases\"] = round((combined_df[\"n_bases_approx_paired\"] / combined_df[\"n_bases_approx_single\"]) , 2)\ncombined_df[\"ratio_read_pairs\"] = round(combined_df[\"n_read_pairs_paired\"] / combined_df[\"n_read_pairs_single\"], 2)\n\n# Order columns\ncombined_df_base_pairs = combined_df[[\"sample\", \"stage\", \"n_bases_approx_single\", \"n_bases_approx_paired\", \"ratio_bases\"]]\n# Display the result\ncombined_df_base_pairs.set_index([\"sample\"])\n\n\n\n\n\n\n\n\n\n\n\n\nstage\nn_bases_approx_single\nn_bases_approx_paired\nratio_bases\n\n\nsample\n\n\n\n\n\n\n\n\n230926Esv_D23-14904-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14905-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14906-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14907-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14908-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14909-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14910-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14911-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14904-1\ncleaned\n3200000\n5000000\n1.56\n\n\n230926Esv_D23-14905-1\ncleaned\n3200000\n5200000\n1.62\n\n\n230926Esv_D23-14906-1\ncleaned\n3200000\n5300000\n1.66\n\n\n230926Esv_D23-14907-1\ncleaned\n3100000\n5300000\n1.71\n\n\n230926Esv_D23-14908-1\ncleaned\n3300000\n5500000\n1.67\n\n\n230926Esv_D23-14909-1\ncleaned\n3100000\n5100000\n1.65\n\n\n230926Esv_D23-14910-1\ncleaned\n3100000\n5400000\n1.74\n\n\n230926Esv_D23-14911-1\ncleaned\n3100000\n5500000\n1.77\n\n\n\n\n\n\n\n\nTable 2.1: Comparison of the number of bases between single-read and paired-end runs, for both raw and cleaned files\n\n\n\n\n\n\nCode\ncombined_df_read_pairs = combined_df[[\"sample\", \"stage\", \"n_read_pairs_single\", \"n_read_pairs_paired\", \"ratio_read_pairs\"]]\n\n\ncombined_df_read_pairs.set_index([\"sample\"])\n\n\n\n\n\n\n\n\n\n\n\n\nstage\nn_read_pairs_single\nn_read_pairs_paired\nratio_read_pairs\n\n\nsample\n\n\n\n\n\n\n\n\n230926Esv_D23-14904-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14905-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14906-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14907-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14908-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14909-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14910-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14911-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14904-1\ncleaned\n24285\n18997\n0.78\n\n\n230926Esv_D23-14905-1\ncleaned\n24495\n19397\n0.79\n\n\n230926Esv_D23-14906-1\ncleaned\n24514\n19843\n0.81\n\n\n230926Esv_D23-14907-1\ncleaned\n24248\n20034\n0.83\n\n\n230926Esv_D23-14908-1\ncleaned\n24626\n20041\n0.81\n\n\n230926Esv_D23-14909-1\ncleaned\n24468\n19672\n0.80\n\n\n230926Esv_D23-14910-1\ncleaned\n24500\n20694\n0.84\n\n\n230926Esv_D23-14911-1\ncleaned\n24514\n21143\n0.86\n\n\n\n\n\n\n\n\nTable 2.2: Comparison of the number of reads between single-read and paired-end runs, for both raw and cleaned files\n\n\n\n\n\n\nComparing output of adapter stats\nComparing adapter contamination (Figure 3.1), the raw_concat percentages are equivalent. MULTIQC running on the paired-end data returned no adapter contamination stats for cleaned reads, suggesting that FASTP did its job well.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\nsns.lineplot(data=se_adapter_stats, x='position', y='pc_adapters', hue='stage', ax=axs[0],units=\"sample\", estimator=None, legend=True)\nsns.lineplot(data=pe_adapter_stats, x='position', y='pc_adapters', hue='stage', style=\"read_pair\", ax=axs[1],units=\"sample\", estimator=None, legend=True)\n\n# Set common properties for both subplots\nfor ax in axs:\n    ax.set_xlabel('Position')\n    ax.set_ylabel('% Adapters')\n    ax.grid(True, linestyle='--', alpha=0.7)\n\n# Set titles for each subplot\naxs[0].set_title('Single-End Adapter Stats')\naxs[1].set_title('Paired-End Adapter Stats')\n# Remove top and right spines for both subplots\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\nfig.tight_layout()\n\n\n\n\n\n\n\n\nFigure 3.1: Adapter contamination along reads\n\n\n\n\n\n\n\nComparing output of quality base stats\nAs expected, the single-read run looks very similar to the forward reads of the paired-end run (Figure 4.1). The Phred scores of the reverse reads are quite bad, with scores consistently under 30 after position 20.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\n\nsns.lineplot(data=se_quality_base_stats, x='position', y='mean_phred_score', hue='stage', style=\"read_pair\", units=\"sample\", ax=axs[0],estimator=None, legend=True)\n\nsns.lineplot(data=pe_quality_base_stats, x='position', y='mean_phred_score', hue='stage', style=\"read_pair\", units=\"sample\", ax=axs[1],estimator=None, legend=True)\n\naxs[0].set_title('Mean phred scores across single-end reads')\naxs[1].set_title('Mean phred scores across paired-end reads')\n\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\nplt.subplots_adjust(hspace=0.3)\n\n\n\n\n\n\n\n\nFigure 4.1: Phred scores along the read\n\n\n\n\n\n\n\nComparing output of quality sequence stats\nPlotting the mean phred score (Figure 5.1), the average Phred scores of the single-read output looks similar to the forward reads of the paired-end run. Notably, there are fewer sequences in the cleaned paired-end forward reads. Again, this is explained by FASTP dropping read pairs where the reverse read was low quality.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\nsns.lineplot(data=se_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', ax=axs[0],units=\"sample\", estimator=None, legend=True)\n\nplt.subplots_adjust(hspace=0.3)\n\n\nsns.lineplot(data=pe_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', ax=axs[1], style=\"read_pair\", units=\"sample\", estimator=None, legend=True)\n\naxs[0].set_title('Mean phred scores of single-end reads')\naxs[1].set_title('Mean phred scores of paired-end reads')\n\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.set_xlim(0, 40)\n    ax.set_ylim(0, 7000)\n\n\n\n\n\n\n\n\nFigure 5.1: Average Phred scores of sequences"
  }
]