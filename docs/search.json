[
  {
    "objectID": "dashboard/index.html",
    "href": "dashboard/index.html",
    "title": "Swab Sampling Recruitment",
    "section": "",
    "text": "Cumulative number of samples collected\n\n\n                                                \n\n\n\n\nSamples collected per day\n\n\n                                                \n\n\n\n\nSampling run metadata\n\n\n\n\n\n\n\nDate\nCollection Site\nCompensation\nSamples collected\nSampling duration\nSwabs per hour\n\n\n\n\nNovember 07, 2024\nMassachussetts Institute of Technology\n$2\n33\n0:47\n42\n\n\nOctober 31, 2024\nMassachussetts Institute of Technology\n$2\n30\n1:08\n26\n\n\nOctober 10, 2024\nMassachussetts Institute of Technology\n$2\n28\n0:43\n39\n\n\nAugust 16, 2024\nKendall Square\n$5\n27\n0:36\n45\n\n\nJuly 16, 2024\nKendall Square\n$5\n23\n1:00\n23\n\n\nJune 18, 2024\nKendall Square\n$5\n27\n0:41\n40\n\n\nJune 17, 2024\nKendall Square\n$5\n26\n0:53\n29\n\n\nMay 28, 2024\nKendall Square\n$5\n23\n0:32\n43\n\n\nMay 24, 2024\nKendall Square\n$5\n19\n0:40\n29\n\n\nMay 21, 2024\nKendall Square\n$5\n26\n1:58\n13"
  },
  {
    "objectID": "posts/2024-10-24-mgs-single-read-eval/index.html",
    "href": "posts/2024-10-24-mgs-single-read-eval/index.html",
    "title": "Testing the single-read version of mgs-workflow’s RAW and CLEAN subworkflows",
    "section": "",
    "text": "I’m adapting mgs-workflow to take in single-read sequencing data. Here I’m checking if: (i) the output of the single-read RAW and CLEAN workflows look as expected, and (ii) if the output of the paired-end version is the same as the output of the test run on dev.\nThe dataset used here was generated from Project Runway samples, with library prep performed at the BMC followed by Element AVITI sequencing. Will previously analyzed this data here. I find that the single-read QC output of the RAW and CLEAN workflows looks as expected, i.e., similar to those of the forward reads in the paired-end run. Differences in the two datasets are mostly mediated by the reverse reads of the paired-end run being low quality, leading to fewer reads and base pairs passing through FASTP, and thus affecting the paired-end QC measures.\nI will amend the PROFILE subworkflow of mgs-workflow next.\n\nIntroduction\nThe single-end dataset simply consists of the forward reads of our usual test dataset. Additionally, I work with the paired-end test dataset, run on the single-read-raw pipeline, and the same dataset run with the master branch of mgs-workflow.\nI compared the qc output of the two paired-end runs, and they are identical, suggesting that the addition of single-read functionality doesn’t impede mgs-workflow runs on paired-end data.\n\n\nCode\nsingle_read_dir = \"mgs-results/test_single_read\"\npaired_read_dir = \"mgs-results/test_paired_end\"\ntest_dir = \"mgs-results/test\"\n\nse_output_dir = os.path.join(single_read_dir, \"output\")\npe_output_dir = os.path.join(paired_read_dir, \"output\")\ntest_output_dir = os.path.join(test_dir, \"output\")\n\nse_results_dir = os.path.join(se_output_dir, \"results\")\npe_results_dir = os.path.join(pe_output_dir, \"results\")\ntest_results_dir = os.path.join(test_output_dir, \"results\")\n\nse_basic_stats_path = os.path.join(se_results_dir, \"qc_basic_stats.tsv.gz\")\nse_adapter_stats_path = os.path.join(se_results_dir, \"qc_adapter_stats.tsv.gz\")\nse_quality_base_stats_path = os.path.join(se_results_dir, \"qc_quality_base_stats.tsv.gz\")\nse_quality_seq_stats_path = os.path.join(se_results_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\npe_basic_stats_path = os.path.join(pe_results_dir, \"qc_basic_stats.tsv.gz\")\npe_adapter_stats_path = os.path.join(pe_results_dir, \"qc_adapter_stats.tsv.gz\")\npe_quality_base_stats_path = os.path.join(pe_results_dir, \"qc_quality_base_stats.tsv.gz\")\npe_quality_seq_stats_path = os.path.join(pe_results_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\n\ntest_basic_stats_path = os.path.join(test_results_dir, \"qc_basic_stats.tsv.gz\")\ntest_adapter_stats_path = os.path.join(test_results_dir, \"qc_adapter_stats.tsv.gz\")\ntest_quality_base_stats_path = os.path.join(test_results_dir, \"qc_quality_base_stats.tsv.gz\")\ntest_quality_seq_stats_path = os.path.join(test_results_dir, \"qc_quality_sequence_stats.tsv.gz\")\n\n\n\n\nAssessing basic stats for both raw and cleaned reads\n\n\nCode\nse_basic_stats = pd.read_csv(se_basic_stats_path, sep='\\t')\npe_basic_stats = pd.read_csv(pe_basic_stats_path, sep='\\t')\ntest_basic_stats = pd.read_csv(test_basic_stats_path, sep='\\t')\n\n\nComparing the basic stats of the single-read version to the paired-end version, the most notable difference is paired-end data losing more bases and reads through FASTP cleaning. Accounting for paired-end reads containing twice as many base pairs, cleaned paired-end read files contain 16.4% fewer bases than cleaned single-end read files. This is largely due to FASTP dropping low-quality read pairs, with the number of cleaned paired-end reads 18.5% lower than the number of cleaned single-end reads. See Table 2.1 and Table 2.2 for per-sample statistics.\nMy current hypothesis for this pattern is that the reverse reads are very low quality, as seen in Figure 4.1, leading FASTP to drop many of the read pairs with a low-quality reverse read. I won’t investigate this further for now, but it suggests we should use a new test dataset that has high-quality forward and reverse reads. Harmon is working on this, which is great.\n\n\nCode\ncombined_df = se_basic_stats[[\"sample\", \"n_bases_approx\", \"stage\", \"n_read_pairs\"]].merge(\n    pe_basic_stats[[\"sample\", \"n_bases_approx\", \"stage\", \"n_read_pairs\"]],\n    on=[\"sample\", \"stage\"],\n    suffixes=[\"_single\", \"_paired\"]\n)\n\ncombined_df[\"ratio_bases\"] = round((combined_df[\"n_bases_approx_paired\"] / combined_df[\"n_bases_approx_single\"]) , 2)\ncombined_df[\"ratio_read_pairs\"] = round(combined_df[\"n_read_pairs_paired\"] / combined_df[\"n_read_pairs_single\"], 2)\n\n# Order columns\ncombined_df_base_pairs = combined_df[[\"sample\", \"stage\", \"n_bases_approx_single\", \"n_bases_approx_paired\", \"ratio_bases\"]]\n# Display the result\ncombined_df_base_pairs.set_index([\"sample\"])\n\n\n\n\n\n\n\n\n\n\n\n\nstage\nn_bases_approx_single\nn_bases_approx_paired\nratio_bases\n\n\nsample\n\n\n\n\n\n\n\n\n230926Esv_D23-14909-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14907-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14906-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14905-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14908-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14904-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14911-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14910-1\nraw_concat\n3700000\n7400000\n2.00\n\n\n230926Esv_D23-14907-1\ncleaned\n3300000\n6600000\n2.00\n\n\n230926Esv_D23-14906-1\ncleaned\n3400000\n6600000\n1.94\n\n\n230926Esv_D23-14908-1\ncleaned\n3400000\n6800000\n2.00\n\n\n230926Esv_D23-14905-1\ncleaned\n3400000\n6600000\n1.94\n\n\n230926Esv_D23-14911-1\ncleaned\n3300000\n6500000\n1.97\n\n\n230926Esv_D23-14904-1\ncleaned\n3300000\n6600000\n2.00\n\n\n230926Esv_D23-14910-1\ncleaned\n3300000\n6600000\n2.00\n\n\n230926Esv_D23-14909-1\ncleaned\n3300000\n6400000\n1.94\n\n\n\n\n\n\n\n\nTable 2.1: Comparison of the number of bases between single-read and paired-end runs, for both raw and cleaned files\n\n\n\n\n\n\nCode\ncombined_df_read_pairs = combined_df[[\"sample\", \"stage\", \"n_read_pairs_single\", \"n_read_pairs_paired\", \"ratio_read_pairs\"]]\n\n\ncombined_df_read_pairs.set_index([\"sample\"])\n\n\n\n\n\n\n\n\n\n\n\n\nstage\nn_read_pairs_single\nn_read_pairs_paired\nratio_read_pairs\n\n\nsample\n\n\n\n\n\n\n\n\n230926Esv_D23-14909-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14907-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14906-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14905-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14908-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14904-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14911-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14910-1\nraw_concat\n25000\n25000\n1.00\n\n\n230926Esv_D23-14907-1\ncleaned\n24580\n24378\n0.99\n\n\n230926Esv_D23-14906-1\ncleaned\n24667\n24394\n0.99\n\n\n230926Esv_D23-14908-1\ncleaned\n24775\n24438\n0.99\n\n\n230926Esv_D23-14905-1\ncleaned\n24659\n24375\n0.99\n\n\n230926Esv_D23-14911-1\ncleaned\n24708\n24524\n0.99\n\n\n230926Esv_D23-14904-1\ncleaned\n24463\n24136\n0.99\n\n\n230926Esv_D23-14910-1\ncleaned\n24722\n24457\n0.99\n\n\n230926Esv_D23-14909-1\ncleaned\n24622\n24263\n0.99\n\n\n\n\n\n\n\n\nTable 2.2: Comparison of the number of reads between single-read and paired-end runs, for both raw and cleaned files\n\n\n\n\n\n\nComparing adapter contamination stats\nComparing adapter contamination (Figure 3.1) between single-read and paired-end runs, the raw_concat and cleaned adapter contaminations show similar trends.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\npe_adapter_stats[\"fwd_rev\"] = pe_adapter_stats[\"file\"].apply(lambda x: \"forward\" if \"_1\" in x else \"reverse\")\nsns.lineplot(data=se_adapter_stats, x='position', y='pc_adapters', hue='stage', ax=axs[0],units=\"sample\", estimator=None, legend=True)\nsns.lineplot(data=pe_adapter_stats, x='position', y='pc_adapters', hue='stage', style=\"fwd_rev\", ax=axs[1],units=\"sample\", estimator=None, legend=True)\n\n# Set common properties for both subplots\nfor ax in axs:\n    ax.set_xlabel('Position')\n    ax.set_ylabel('% Adapters')\n    ax.grid(True, linestyle='--', alpha=0.7)\n\n# Set titles for each subplot\naxs[0].set_title('Single-End Adapter Stats')\naxs[1].set_title('Paired-End Adapter Stats')\n# Remove top and right spines for both subplots\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\nfig.tight_layout()\n\n\n\n\n\n\n\n\nFigure 3.1: Adapter contamination along reads\n\n\n\n\n\n\n\nComparing base quality stats\nThis plot has become less meaningful with the inability to distinguish between forward and reverse reads. I might rerun this plot once we have a new, better test dataset.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\n\npe_quality_base_stats[\"fwd_rev\"] = pe_quality_base_stats[\"file\"].apply(lambda x: \"forward\" if \"_1\" in x else \"reverse\")\n\nsns.lineplot(data=se_quality_base_stats, x='position', y='mean_phred_score', hue='stage', units=\"sample\", ax=axs[0],estimator=None, legend=True)\n\nsns.lineplot(data=pe_quality_base_stats, x='position', y='mean_phred_score', hue='stage', style=\"fwd_rev\", units=\"sample\", ax=axs[1],estimator=None, legend=True)\n\naxs[0].set_title('Mean phred scores across single-end reads')\naxs[1].set_title('Mean phred scores across paired-end reads')\n\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\nplt.subplots_adjust(hspace=0.3)\n\n\n\n\n\n\n\n\nFigure 4.1: Phred scores along the read\n\n\n\n\n\n\n\nComparing sequence quality stats\nPlotting the mean phred score (Figure 5.1) again a comparison is hard due to the inability to distinguish between forward and reverse reads in the paired-end data. Nevertheless, in aggregate the single-read data has higher quality scores, which is expected given that the foward reads of the test dataset, whcih make up the single-read data, have higher quality scores than the reverse reads.\n\n\nCode\nfig, axs = plt.subplots(2, 1, dpi=300, figsize=(10, 8))\nsns.lineplot(data=se_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', ax=axs[0],units=\"sample\", estimator=None, legend=True)\n\nplt.subplots_adjust(hspace=0.3)\n\npe_quality_seq_stats[\"fwd_rev\"] = pe_quality_seq_stats[\"file\"].apply(lambda x: \"forward\" if \"_1\" in x else \"reverse\")\n\nsns.lineplot(data=pe_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', style=\"fwd_rev\", units=\"sample\", ax=axs[1], estimator=None, legend=True)\n\naxs[0].set_title('Mean phred scores of single-end reads')\naxs[1].set_title('Mean phred scores of paired-end reads')\n\nfor ax in axs:\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.set_xlim(0, 40)\n    ax.set_ylim(0, 7000)\n\n\n\n\n\n\n\n\nFigure 5.1: Average Phred scores of sequences"
  },
  {
    "objectID": "posts/2024-10-28-mgs-taxonomy-eval/index.html",
    "href": "posts/2024-10-28-mgs-taxonomy-eval/index.html",
    "title": "Testing the single-read version of mgs-workflow’s PROFILE subworkflow",
    "section": "",
    "text": "I’m adapting mgs-workflow to take in single-read sequencing data. Here I’m checking if: i) the output of the single-read PROFILE workflow looks as expected, and ii) if the output of the paired-end version is the same as the output of the test run on dev.\nAs in my previous post, the dataset the workflows are run on is based on Project Runway samples, with library prep performed at the BMC followed by Element AVITI sequencing. Will previously analyzed this test dataset here, using an early version of mgs-workflow.\nLooking at Kingdom-level composition in both Kraken and Bracken results, the single-read output looks as expected, i.e., similar to the paired-end output. The paired-end run looks the same as when using the original run workflow, so addition of single-read functionality doesn’t impede mgs-workflow runs on paired-end data.\nI will amend the HV subworkflow of mgs-workflow next.\n\nIntroduction\nThe single-end dataset simply consists of the forward reads of our usual test dataset. Additionally, I work with the paired-end test dataset. Both of these are run through run_dev_se.nf, a shorter version of run.nf that only includes RAW, CLEAN, and PROFILE. run_dev_se.nf contains a read_type parameter, which is set to single_end for the single-end run, and paired_end for the paired-end run. Finally, the paired-end run is compared to the output of a normal test run using run.nf.\n\n\nCode\nsingle_read_dir = \"~/code/simons-notebook/posts/2024-10-28-mgs-taxonomy-eval/mgs-results/test_single_read\"\npaired_read_dir = \"~/code/simons-notebook/posts/2024-10-28-mgs-taxonomy-eval/mgs-results/test_paired_end\"\ntest_dir = \"~/code/simons-notebook/posts/2024-10-28-mgs-taxonomy-eval/mgs-results/test\"\n\nse_output_dir = os.path.join(single_read_dir, \"output\")\npe_output_dir = os.path.join(paired_read_dir, \"output\")\ntest_output_dir = os.path.join(test_dir, \"output\")\n\nse_results_dir = os.path.join(se_output_dir, \"results\")\npe_results_dir = os.path.join(pe_output_dir, \"results\")\ntest_results_dir = os.path.join(test_output_dir, \"results\")\n\nse_bracken_path = os.path.join(se_results_dir, \"bracken_reports_merged.tsv.gz\")\npe_bracken_path = os.path.join(pe_results_dir, \"bracken_reports_merged.tsv.gz\")\ntest_bracken_path = os.path.join(test_results_dir, \"bracken_reports_merged.tsv.gz\")\n\nse_kraken_path = os.path.join(se_results_dir, \"kraken_reports_merged.tsv.gz\")\npe_kraken_path = os.path.join(pe_results_dir, \"kraken_reports_merged.tsv.gz\")\ntest_kraken_path = os.path.join(test_results_dir, \"kraken_reports_merged.tsv.gz\")\n\n\n\n\nAssessing Kraken output files\nFirst off, we can check if the high-level taxonomy statistics are the same between the single-read, paired-end, and default test runs. For this we use the kraken_reports_merged.tsv.gz files, which gives a detailed taxonomic breakdown.\nOnly looking at the kingdom-level, the single-read and paired-end read results look nearly identical, which is what we’d expect. As seen in the previous notebook, in the single-read run more total reads survive FASTP cleaning, leading to a higher number of reads that end up getting classified.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Calculate percentages\ncols_to_normalize = ['Bacteria (Ribosomal)', 'Bacteria (Non-ribosomal)',\n                     'Viruses (Ribosomal)', 'Viruses (Non-ribosomal)',\n                     'Archaea (Ribosomal)', 'Archaea (Non-ribosomal)',\n                     'Eukaryota (Ribosomal)', 'Eukaryota (Non-ribosomal)',\n                     'Unclassified (Ribosomal)', 'Unclassified (Non-ribosomal)']\n\n# Create the horizontal stacked bar plot\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 8), dpi=300)  #\n\n# Plot stacked bars horizontally\nfor ax, df, title in zip([ax1, ax2, ax3], [se_kraken_plot_df, pe_kraken_plot_df, test_kraken_plot_df], [\"single-end\", \"paired-end\", \"normal run\"]):\n    df_pct = df[cols_to_normalize].div(df[cols_to_normalize].sum(axis=1), axis=0) * 100\n\n    left = np.zeros(len(df))\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    for i, column in enumerate(cols_to_normalize):\n        ax.barh(df['sample'], df_pct[column], left=left,\n                label=column.capitalize(), color=colors[i])\n        left += df_pct[column]\n    for i, row in df.iterrows():\n        ax.text(101, i, f'{int(row[\"Total Reads\"]):,}',\n                va='center', ha='left')\n\n    # Customize the plot\n    # ax.set_yticks(rotation=0)  # No rotation needed for horizontal bars\n\n    ax.set_title(title)\n    ax.set_xlim(0, 100)\n\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    # Add some padding to the right for the legend\nax3.set_xlabel('Percentage (%)')\nax1.text(101, 9, 'Number of\\nreads', va='center', ha='left')\nax3.legend(title='Taxonomy', bbox_to_anchor=(0.5, -0.8), loc='center', ncol=3)\nplt.tight_layout()\n\n\n/var/folders/gm/txqg8t5d57z34sqfjcvpcjj00000gn/T/ipykernel_5241/946545511.py:41: UserWarning:\n\nTight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n\n\n\n\n\n\n\n\n\nFigure 2.1: Kingdom-level read distribution (Kraken)\n\n\n\n\n\n\n\nAssessing Bracken output files\nThe other output of the PROFILE subworkflow is the bracken_reports_merged.tsv.gz file, which gives Bracken-summarized and corrected kingdom-level counts, based on the Kraken output. Again, single-read results look very similar to paired-end results. The only difference is a slightly higher share of non-ribosomal bacterial reads in the single-read run. I am uncertain to why that is, maybe the reads that FASTP removed in the paired-end run were enriched for non-ribosomal bacterial reads?\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Calculate percentages\ncols_to_normalize = ['Bacteria (Ribosomal)', 'Bacteria (Non-ribosomal)',\n                     'Viruses (Ribosomal)', 'Viruses (Non-ribosomal)',\n                     'Archaea (Ribosomal)', 'Archaea (Non-ribosomal)',\n                     'Eukaryota (Ribosomal)', 'Eukaryota (Non-ribosomal)']\n\n# Create the horizontal stacked bar plot\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 8), dpi=300)  #\n\n# Plot stacked bars horizontally\nfor ax, df, title in zip([ax1, ax2, ax3], [se_bracken_plot_df, pe_bracken_plot_df, test_bracken_plot_df], [\"single-end\", \"paired-end\", \"normal run\"]):\n    df_pct = df[cols_to_normalize].div(df[cols_to_normalize].sum(axis=1), axis=0) * 100\n\n    left = np.zeros(len(df))\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    for i, column in enumerate(cols_to_normalize):\n        ax.barh(df['sample'], df_pct[column], left=left,\n                label=column.capitalize(), color=colors[i])\n        left += df_pct[column]\n    for i, row in df.iterrows():\n        ax.text(101, i, f'{int(row[\"Total Assigned Reads\"]):,}',\n                va='center', ha='left')\n\n    # Customize the plot\n    # ax.set_yticks(rotation=0)  # No rotation needed for horizontal bars\n\n    ax.set_title(title)\n    ax.set_xlim(0, 100)\n\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    # Add some padding to the right for the legend\nax3.set_xlabel('Percentage (%)')\nax1.text(101, 9, 'Number of\\nAssigned\\nreads', va='center', ha='left')\nax3.legend(title='Taxonomy', bbox_to_anchor=(0.5, -0.8), loc='center', ncol=3)\nplt.tight_layout()\n\n\n/var/folders/gm/txqg8t5d57z34sqfjcvpcjj00000gn/T/ipykernel_5241/943950913.py:40: UserWarning:\n\nTight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n\n\n\n\n\n\n\n\n\nFigure 3.1: Kingdom-level read distribution (Bracken)\n\n\n\n\n\n\n\nNext steps\nOverall, the single-read version of the PROFILE workflow seems to work as expected. The next step is to adapt the HV subworkflow."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html",
    "href": "posts/2024-07-25-mbta-ridership/index.html",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "",
    "text": "As part of our swab sampling pilot project, we want to identify stations where we can collect a lot of swab samples in a short amount of time. One way to identify these stations is to look at the number of passengers that enter each station, which the MBTA provides. They give the number of passengers that enter a gated station every 30 minutes. Crucially, this doesn’t tell us how many people leave the station, which would be useful to understand full passenger volume of a station."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#red-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#red-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Red line",
    "text": "Red line\nThe red line is closest to the office and MIT and thus the obvious candidate for sampling. Let’s take a look at the daily ridership, averaged over the month of June 2024, for the red line stations closest to the SecureBio office (Porter, Central, Kendall/MIT, Charles/MGH, Park Street, and Downtown Crossing).\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Porter\", \"Harvard\", \"Central\", \"Kendall/MIT\", \"Charles/MGH\", \"Park Street\", \"Downtown Crossing\"]\n\n\nridership_2024[\"date_dt\"] = pd.to_datetime(ridership_2024[\"service_date\"])\nreference_date = pd.to_datetime(\"1800-06-01\")  # reference date is used as a placeholder, set to an implausible value\nridership_2024[\"time_dt\"] = pd.to_datetime(reference_date.strftime('%Y-%m-%d') + ' ' + ridership_2024[\"time_period\"].str.strip(\"()\"))\nmorning_peak_rides = {}\nevening_peak_rides = {}\n\n# Data represents ridership over the half hour starting at the given time. Adding 15 minutes to create correct center of interval.\nridership_2024[\"time_dt\"] = ridership_2024[\"time_dt\"] + pd.Timedelta(minutes=15)\n\n\nred_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Red Line\"]\njune_2024 = red_line_2024[red_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership_morning = mean_use_per_interval[mean_use_per_interval[\"time_dt\"].dt.hour.between(1, 10)][\"gated_entries\"].max()\n        max_usership_evening = mean_use_per_interval[mean_use_per_interval[\"time_dt\"].dt.hour.between(16, 23)][\"gated_entries\"].max()\n        morning_peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership_morning]\n        evening_peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership_evening]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(station)\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Red Line stations in June 2024\")\nplt.show()\n\n# Morning peaks:\n\nmorning_peak_ride_porter = round(morning_peak_rides[\"Porter\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_porter = morning_peak_rides[\"Porter\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_central = round(morning_peak_rides[\"Central\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_central = morning_peak_rides[\"Central\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_kendall = round(morning_peak_rides[\"Kendall/MIT\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_kendall = morning_peak_rides[\"Kendall/MIT\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nmorning_peak_ride_harvard = round(morning_peak_rides[\"Harvard\"][\"gated_entries\"].values[0])\nmorning_peak_ride_time_harvard = morning_peak_rides[\"Harvard\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\nevening_peak_ride_kendall = round(evening_peak_rides[\"Kendall/MIT\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_kendall = evening_peak_rides[\"Kendall/MIT\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nevening_peak_ride_harvard = round(evening_peak_rides[\"Harvard\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_harvard = evening_peak_rides[\"Harvard\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\nevening_peak_ride_charles = round(evening_peak_rides[\"Charles/MGH\"][\"gated_entries\"].values[0])\nevening_peak_ride_time_charles = evening_peak_rides[\"Charles/MGH\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nCentral, Harvard, and Porter stations see the most ppl entering stations in the morning due to commuters going into the city (304, 275, and 243 from 8:30-9:00, respectively). Kendall/MIT, Charles/MGH, and Harvard see the most people entering in the evening (618, 345, and 482 from 17:00-17:30, respectively). People who take the T from a commuter station in the evening likely arrived at the same station in the evening. We can thus assume that the evening bump in ridership for Kendall and Harvard can be added to the morning bump.\nBased on the data here, Kendall and Harvard station all seem like good stations to do sampling in the morning."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#green-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#green-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Green line",
    "text": "Green line\nThe green line is fairly close to the office (two stations away). Looking at Figure 2, the four Green line stations closest to the nearest Red line station are Government Center, Haymarket, Boylston, and Copley.\n\n\n\n\n\n\nFigure 2: MBTA Subway Map (2013)\n\n\n\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Government Center\", \"Haymarket\", \"Boylston\", \"Copley\"]\npeak_rides = {}\n\n\ngreen_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Green Line\"]\njune_2024 = green_line_2024[green_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n        peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(f\"{station} is more than three stations away from Kendall close to Kendall\")\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\n\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Green Line stations in June 2024\")\nplt.show()\n\npeak_ride_copley = round(peak_rides[\"Copley\"][\"gated_entries\"].values[0])\npeak_ride_time_copley = peak_rides[\"Copley\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_haymarket = round(peak_rides[\"Haymarket\"][\"gated_entries\"].values[0])\npeak_ride_time_haymarket = peak_rides[\"Haymarket\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\nCopley and Government Center see the most ridership (466) and 118 at 17:15, respectively at from 17:00 to 17:30. Again, the same pattern is visible where many people enter stations in the evening, and thus likely leave the station in the evening."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#orange-line",
    "href": "posts/2024-07-25-mbta-ridership/index.html#orange-line",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "Orange line",
    "text": "Orange line\nFinally, let’s look at the Orange line. The Orange line is the furthest away from the office, but it is still only 3 stations away. Let’s again look at the four Orange line stations closest to the office. Additionally I include Back Bay station as that station has a fairly big entrance hall which could be suitable for sampling:\n\n\n\nBack Bay Station\n\n\n\n\nCode\nplt.figure(figsize=(12, 4), dpi=600)\ntarget_stations = [\"Tufts Medical Center\", \"Haymarket\", \"Chinatown\", \"State Street\", \"Back Bay\"]\npeak_rides = {}\n\norange_line_2024 = ridership_2024[ridership_2024[\"route_or_line\"] == \"Orange Line\"]\njune_2024 = orange_line_2024[orange_line_2024[\"date_dt\"].dt.month == 6]\nstations = june_2024[\"station_name\"].unique()\nfor station in stations:\n    if station in target_stations:\n        june_station = june_2024[june_2024[\"station_name\"] == station]\n        mean_use_per_interval = june_station.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n        peak_rides[station] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=station)\n\n    else:\n        if PRINT:\n            print(station)\nax = plt.gca()\nplt.legend()\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval for Orange Line stations in June 2024\")\nplt.show()\n\npeak_ride_back_bay = round(peak_rides[\"Back Bay\"][\"gated_entries\"].values[0])\npeak_ride_time_back_bay = peak_rides[\"Back Bay\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_state_street = round(peak_rides[\"State Street\"][\"gated_entries\"].values[0])\npeak_ride_time_state_street = peak_rides[\"State Street\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\nHere Back Bay and State Street look great, with a peak ridership of 432 and 490 from 17:00 to 17:30."
  },
  {
    "objectID": "posts/2024-07-25-mbta-ridership/index.html#north-and-south-station",
    "href": "posts/2024-07-25-mbta-ridership/index.html#north-and-south-station",
    "title": "Identifying promising MBTA stations for swab sampling: MBTA Ridership",
    "section": "North and South Station",
    "text": "North and South Station\nFinally, let’s look at North Station and South Station. Given that they are connected to the Amtrak network, they might see a lot of traffic. Additionaly we are currently in conversation with the administrators of both stations to do sampling there (though sampling would probaly take place in the train station, not in the subway station).\n\n\nCode\ntarget_stations = [\"North Station\", \"South Station\"]\nplt.figure(figsize=(12, 4), dpi=600)\n\npeak_rides = {}\n\njune_ridership = ridership_2024[ridership_2024[\"date_dt\"].dt.month == 6]\n\nfor station in target_stations:\n    station_ridership = june_ridership[june_ridership[\"station_name\"] == station]\n    lines_in_station = station_ridership[\"route_or_line\"].unique()\n    for line in lines_in_station:\n        line_ridership = station_ridership[station_ridership[\"route_or_line\"] == line]\n        mean_use_per_interval = line_ridership.groupby(\"time_dt\")[\"gated_entries\"].mean()\n        mean_use_per_interval = mean_use_per_interval.reset_index()\n        max_usership = mean_use_per_interval[\"gated_entries\"].max()\n\n        peak_rides[(station, line)] = mean_use_per_interval[mean_use_per_interval[\"gated_entries\"] == max_usership]\n\n        line_to_sns_color_dict = {\"Green Line\": \"#58ac6c\", \"Orange Line\": \"#f79646\", \"Red Line\": \"#d62728\", \"Silver Line\": \"#647c9a\"}\n        plt.plot(mean_use_per_interval[\"time_dt\"], mean_use_per_interval[\"gated_entries\"], label=f\"{station} ({line})\", color=line_to_sns_color_dict[line])\n\nax = plt.gca()\nplt.legend()\n\ny_lims = (0, 700)\nfor y in range(y_lims[0], y_lims[1], 100):\n    plt.axhline(y=y, color='gray', linestyle='--', zorder=-1, linewidth=0.5)\n\nplt.ylim(y_lims)\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\nplt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=2))\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.xlabel(\"Time of day\")\nplt.ylabel(\"Number of passengers per half-hour\")\nplt.title(\"Average number of passengers per half-hour interval at North and South Stations in June 2024\")\n\npeak_ride_north_green = round(peak_rides[\"North Station\", \"Green Line\"][\"gated_entries\"].values[0])\npeak_ride_time_north_green = peak_rides[\"North Station\", \"Green Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_north_orange = round(peak_rides[\"North Station\", \"Orange Line\"][\"gated_entries\"].values[0])\npeak_ride_time_north_orange = peak_rides[\"North Station\", \"Orange Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_south_red = round(peak_rides[\"South Station\", \"Red Line\"][\"gated_entries\"].values[0])\npeak_ride_time_south_red = peak_rides[\"South Station\", \"Red Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\npeak_ride_south_silver = round(peak_rides[\"South Station\", \"Silver Line\"][\"gated_entries\"].values[0])\npeak_ride_time_south_silver = peak_rides[\"South Station\", \"Silver Line\"][\"time_dt\"].dt.time.values[0].strftime(\"%H:%M\")\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nFor both stations and lines, peak traffic is again at 17:00 to 17:30, with 156 and 304 riders at North Station’s Green and Orange line, and 498 and 213 riders at South Station’s Red and Silver line, respectively."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simon's Public NAO Notebook",
    "section": "",
    "text": "Testing the ONT version of mgs-workflow’s RAW and CLEAN subworkflows\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\n\n\n\n\n\n\nQuality control of Zephyr 5b\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\n\n\n\n\n\n\nTesting the single-read version of mgs-workflow’s PROFILE subworkflow\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\n\n\n\n\n\n\nTesting the single-read version of mgs-workflow’s RAW and CLEAN subworkflows\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying promising MBTA stations for swab sampling: MBTA Ridership\n\n\nHow many passengers use different MBTA stations?\n\n\n\nMBTA\n\n\nSwab sampling\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nSimon Grimm\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-12-08-mgs-ont-raw-eval/index.html",
    "href": "posts/2024-12-08-mgs-ont-raw-eval/index.html",
    "title": "Testing the ONT version of mgs-workflow’s RAW and CLEAN subworkflows",
    "section": "",
    "text": "After spending some time adapting mgs-workflow to take in single-read sequencing data (see here and here), I’m now working to adapt the pipeline to take in long-read Oxford Nanopore sequencing data.\nThe dataset used here is based on our sequencing data, generated from swab samples collected on 2024-10-10.I’m starting with the RAW and CLEAN workflows. Outputs look as expected, but I want to compare the results with the default HTML-rendered MultiQC output.\n\nAssessing basic stats for both raw and cleaned reads\nBasic statistics look fine. The higher number of duplicates does suggest that we should make sure that deduplication is working properly in the later stages of the pipeline.\n\n\nCode\ntest_basic_stats[\"barcode-div\"] = test_basic_stats[\"sample\"].apply(lambda x: f\"{x.split('-')[-2]}-div{x.split('-')[-1].replace('div000', '')}\")\ntest_basic_stats_tbl= test_basic_stats[[\"barcode-div\", \"percent_gc\", \"mean_seq_len\", \"n_read_pairs\", \"percent_duplicates\", \"n_bases_approx\", \"stage\"]]\ntest_basic_stats_tbl = test_basic_stats_tbl[test_basic_stats_tbl[\"stage\"] == \"raw_concat\"]\ntest_basic_stats_tbl = test_basic_stats_tbl.drop(columns=[\"stage\"])\n\n\n# Display the result\ntest_basic_stats_tbl.sort_values(by=\"barcode-div\").set_index([\"barcode-div\"])\n\n\n\n\n\n\n\n\n\n\n\n\npercent_gc\nmean_seq_len\nn_read_pairs\npercent_duplicates\nn_bases_approx\n\n\nbarcode-div\n\n\n\n\n\n\n\n\n\n05-div0\n40\n3570.319471\n6733\n38.378138\n23800000\n\n\n05-div1\n39\n3559.099024\n7483\n40.037418\n26300000\n\n\n05-div2\n39\n3488.091615\n7990\n40.287860\n27500000\n\n\n05-div3\n40\n3401.577239\n7671\n38.247947\n25700000\n\n\n05-div4\n39\n3434.920247\n6959\n37.232361\n23600000\n\n\n05-div5\n40\n3428.614773\n6661\n36.465996\n22500000\n\n\n05-div6\n40\n3593.581991\n2421\n24.452705\n8600000\n\n\n\n\n\n\n\n\nTable 1.1: Summary statistics for raw ONT read\n\n\n\n\n\n\nAdapter contamination stats\nA lot of reads show polya tails. I will check in with Vanessa to see if this level of contamination is to be expected.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\nsns.lineplot(data=test_adapter_stats, x='position', y='pc_adapters', hue='stage', ax=ax,units=\"sample\", style=\"adapter\", estimator=None, legend=True)\n\n# Set common properties for both subplots\nax.set_xlabel('Position')\nax.set_ylabel('% Adapters')\nax.grid(True, linestyle='--', alpha=0.7)\n\n# Set titles for each subplot\nax.set_title('Adapter contamination along reads')\n# Remove top and right spines for both subplots\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfig.tight_layout()\n\n\n\n\n\nFigure 2.1: Adapter contamination along reads\n\n\n\n\n\n\n\n\n\n\nComparing base quality stats\nPhred scores along the read look good! We have long, clean reads that reach up to 5000bp at quality scores of 35 and above.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\n\n\nsns.lineplot(data=test_quality_base_stats, x='position', y='mean_phred_score', hue='stage', units=\"sample\", ax=ax,estimator=None, legend=True)\n\n# ax.set_title('Mean phred scores along reads')\n\n# Add horizontal lines at Phred scores 10, 20, 30, 40\nax.grid(True, linestyle='--', alpha=0.7)\n\n# for phred in [10, 20, 30, 40]:\n    # ax.axhline(y=phred, color='gray', linestyle='--', alpha=0.5, linewidth=1, zorder=-2)\n\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 3.1: Mean phred scores along the read\n\n\n\n\n\n\n\n\n\n\nComparing sequence quality stats\nAs expected given Figure 3.1, the number of sequences with a decent average Phred score looks good. Filtlong does succesfully remove low-quality sequences, though the average quality score we are currently using is probably too low.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\nsns.lineplot(data=test_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', ax=ax,units=\"sample\", estimator=None, legend=True)\nax.grid(True, linestyle='--', alpha=0.7)\n\n\n\n# Add horizontal lines at 200, 400, 600\n# for n_seq in [200, 400, 600]:\n    # ax.axhline(y=n_seq, color='gray', linestyle='--', alpha=0.5, linewidth=1, zorder=-2)\n\n\n# ax.set_title('Average Phred scores of sequences')\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 4.1: Average Phred scores of sequences\n\n\n\n\n\n\n\n\n\n\nRead lengths\nAfter cleaning, read lengths are under 200bp are removed. There are two cleaned samples, that still show data at under 200bp. This could be an artefact of how MultiQC summarises length statistics for plotting, but it’s worth following up here by manually checking the read length data.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\nsns.lineplot(data=test_read_lengths, x='length', y='n_sequences', hue='stage', ax=ax, units=\"sample\", estimator=None, legend=True)\nax.grid(True, linestyle='--', alpha=0.7)\n\n\nax.set_xlim(0, 7500)\n\nax.set_xlabel('Read length')\nax.set_ylabel('Number of sequences')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 5.1: Read lengths"
  },
  {
    "objectID": "posts/2024-12-09-zephyr-5b-qc/index.html",
    "href": "posts/2024-12-09-zephyr-5b-qc/index.html",
    "title": "Quality control of Zephyr 5b",
    "section": "",
    "text": "We can now run mgs-workflow’s QC and filtering steps on ONT data. Here is a quick analysis of the results of the Zephyr 5b run from November 13, 2024. I find very high polyA contamination, a lot of very short reads (&lt;500bp), but good quality scores for those reads that reach the expected length of 4000bp.\n\nAssessing basic stats for both raw and cleaned reads\nNotably, the GC content and mean sequence length of most sequencing files are fairly low (~20% GC, mean length ~ 320 bp). We’d expect mean sequence length to be close to 4kbp, and the GC content to be closer to 40%. Duplication rates are also fairly high, with up to 60%.\n\n\nCode\ntest_basic_stats[\"barcode-div\"] = test_basic_stats[\"sample\"].apply(lambda x: f\"{x.split('-')[-2]}-div{x.split('-')[-1].replace('div000', '')}\")\ntest_basic_stats_tbl= test_basic_stats[[\"barcode-div\", \"percent_gc\", \"mean_seq_len\", \"n_read_pairs\", \"percent_duplicates\", \"n_bases_approx\", \"stage\"]]\ntest_basic_stats_tbl = test_basic_stats_tbl[test_basic_stats_tbl[\"stage\"] == \"raw_concat\"]\ntest_basic_stats_tbl = test_basic_stats_tbl.drop(columns=[\"stage\"])\n\n\n# Display the result\ntest_basic_stats_tbl.sort_values(by=\"barcode-div\").set_index([\"barcode-div\"])\n\n\n\n\n\n\n\n\n\n\n\n\npercent_gc\nmean_seq_len\nn_read_pairs\npercent_duplicates\nn_bases_approx\n\n\nbarcode-div\n\n\n\n\n\n\n\n\n\n12-div1\n22\n395.454956\n7315\n69.022556\n2200000.0\n\n\n12-div2\n17\n288.020629\n7562\n70.801375\n2000000.0\n\n\n12-div3\n20\n298.447495\n6666\n68.616862\n1800000.0\n\n\n12-div4\n18\n354.134247\n4745\n67.481560\n1200000.0\n\n\n13-div1\n17\n247.800969\n4748\n63.668913\n1000000.0\n\n\n13-div2\n23\n5065.290848\n4786\n65.461763\n1400000.0\n\n\n13-div3\n16\n318.018220\n4281\n63.092735\n923.4\n\n\n13-div4\n14\n319.472310\n3178\n63.184393\n699.1\n\n\n\n\n\n\n\n\nTable 1.1: Summary statistics for raw ONT read\n\n\n\n\n\n\nAdapter contamination stats\nPolyA contamination is very high. The higher contamination levels in cleaned reads may be due to the removal of very low-complexity reads that didn’t get classified as being polyA-contaminated.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\nsns.lineplot(data=test_adapter_stats, x='position', y='pc_adapters', hue='stage', ax=ax,units=\"sample\", style=\"adapter\", estimator=None, legend=True)\n\n# Set common properties for both subplots\nax.set_xlabel('Position')\nax.set_ylabel('% Adapters')\nax.grid(True, linestyle='--', alpha=0.7)\n\nax.set_xlim(0, 15000)\n\n# Set titles for each subplot\nax.set_title('Adapter contamination along reads')\n# Remove top and right spines for both subplots\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfig.tight_layout()\n\n\n\n\n\nFigure 2.1: PolyA/PolyQ contamination along reads\n\n\n\n\n\n\n\n\n\n\nComparing base quality stats\nMost reads have a good average Phred score up until around 6000bp, dropping off thereafter. Cleaning increases Phred scores for most samples. The low scores at the start of the reads are likely due to the large number of short low-quality reads.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\n\n\nsns.lineplot(data=test_quality_base_stats, x='position', y='mean_phred_score', hue='stage', units=\"sample\", ax=ax,estimator=None, legend=True)\n\n# ax.set_title('Mean phred scores along reads')\n\n# Add horizontal lines at Phred scores 10, 20, 30, 40\nax.grid(True, linestyle='--', alpha=0.7)\n\nax.set_xlim(0, 15000)\n\n# for phred in [10, 20, 30, 40]:\n    # ax.axhline(y=phred, color='gray', linestyle='--', alpha=0.5, linewidth=1, zorder=-2)\n\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 3.1: Mean phred scores along the read\n\n\n\n\n\n\n\n\n\n\nComparing sequence quality stats\nThe modal mean phred score for reads is around 24, which isn’t great. Potentially this average would be improved by I) stronger trimming of reads once their quality drops below a certain threshold, and II) removal of reads that are short, and probably very low quality (see the low quality scores of over the first few hundred base pair positions in Figure 3.1).\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\nsns.lineplot(data=test_quality_seq_stats, x='mean_phred_score', y='n_sequences', hue='stage', ax=ax,units=\"sample\", estimator=None, legend=True)\nax.grid(True, linestyle='--', alpha=0.7)\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 4.1: Average Phred scores of sequences\n\n\n\n\n\n\n\n\n\n\nRead lengths\nAs observed in the initial summary stats, most reads in the sample are very short (Figure 5.1). Zooming in in Figure 5.2 shows that there are a couple of reads that have the expected length of 4000bp.\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\ntest_read_lengths_cleaned = test_read_lengths[test_read_lengths[\"stage\"] == \"cleaned\"]\n\ntest_read_lengths_cleaned[\"Treatment\"] = test_read_lengths_cleaned[\"sample\"].apply(lambda x: \"Filtration + Concentration\" if \"12\" in x else \"Filtration\")\n\nsns.lineplot(data=test_read_lengths_cleaned, x='length', y='n_sequences', hue='Treatment', ax=ax, units=\"sample\", estimator=None, legend=True)\nax.grid(True, linestyle='--', alpha=0.7)\n\n\nax.set_xlim(0, 6500)\n\nax.set_ylim(0, 1000)\n\nax.set_xlabel('Read length')\nax.set_ylabel('Number of sequences')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 5.1: Read lengths (high-level)\n\n\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots(dpi=300, figsize=(10, 4))\ntest_read_lengths_cleaned = test_read_lengths[test_read_lengths[\"stage\"] == \"cleaned\"]\n\ntest_read_lengths_cleaned[\"Treatment\"] = test_read_lengths_cleaned[\"sample\"].apply(lambda x: \"Filtration + Concentration\" if \"12\" in x else \"Filtration\")\n\nsns.lineplot(data=test_read_lengths_cleaned, x='length', y='n_sequences', hue='Treatment', ax=ax, units=\"sample\", estimator=None, legend=True)\nax.grid(True, linestyle='--', alpha=0.7)\n\n\nax.set_xlim(500, 8000)\n\nax.set_ylim(0, 50)\n\nax.set_xlabel('Read length')\nax.set_ylabel('Number of sequences')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n\n\n\n\nFigure 5.2: Read lengths (zoomed in)"
  }
]