{
  "hash": "3712dea6ef1185e0b2230539deca85af",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Figures for swab sampling post\nsubtitle: ''\nauthor: Simon Grimm\ndate: '2024-05-08'\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    df-print: paged\neditor: visual\ntoc: true\nfilters:\n  - black-formatter\n---\n\n\n::: {#define-functions .cell execution_count=2}\n``` {.python .cell-code}\nN_SWABS = [50, 100, 200]\nSWAB_STUDY_TITLES = [\n    \"Lu et al. 2021\",\n    \"Babiker et al. 2020\",\n    \"Mostafa et al. 2020\",\n    \"Rodriguez et al. 2021\",\n]\n\nWW_STUDY_TITLES = [\"Rothman et al. 2021\", \"Crits-Christoph et al. 2021\"]\n\n\ndef logit(x):\n    return np.log(x / (1 - x))\n\n\ndef logistic(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef simulate_p2ra_many(\n    ra_lists=[0.01], sample_populations=[100], n_simulations=1000\n) -> pd.DataFrame:\n    results = defaultdict(list)\n    for sample_pop in sample_populations:\n        for _ in range(n_simulations):\n            results[sample_pop].append(simulate_p2ra(sample_pop, ra_lists))\n    for key, values in results.items():\n        results[key] = sorted(values)\n    df = pd.DataFrame(results)\n    return df\n\n\ndef simulate_p2ra(sample_pop=100, ra_lists=[0.01]):\n    target_incidence_p_w = 0.01\n    shedding_duration_w = 2.4\n\n    prevalence = target_incidence_p_w * shedding_duration_w\n    n_sick = np.random.poisson(sample_pop * prevalence)\n\n    if n_sick == 0:\n        return 0\n    ra_sick = 0\n    for _ in range(n_sick):\n        observation = np.random.choice(ra_lists)\n        ra_sick += observation\n    ra_sick = ra_sick / n_sick\n    relative_abundance = n_sick / sample_pop * ra_sick\n\n    return relative_abundance\n\n\ndef plot_medians(ax, medians):\n    patches = ax.collections\n    for patch, median in zip(patches, medians):\n        for path in patch.get_paths():\n            vertices = path.vertices\n            x_mid = median\n            closest_x = min(vertices[:, 0], key=lambda x: abs(x - x_mid))\n            y_upper = max(vertices[vertices[:, 0] == closest_x, 1])\n            y_lower = min(vertices[vertices[:, 0] == closest_x, 1])\n            ax.plot([x_mid, x_mid], [y_lower, y_upper], color=\"white\", linewidth=1.5)\n\n\ndef return_studies():\n    df_op_lu = pd.read_csv(\"data/lu_throat_ct_mgs.tsv\", sep=\"\\t\", skiprows=1)\n    df_op_lu.rename(\n        columns={\"SCV-2 Relative Abundance\": \"scv2_ra\", \"Ct value\": \"scv2_ct\"},\n        inplace=True,\n    )\n    df_op_lu[[\"patient_status\", \"swab_type\", \"Study\"]] = [\n        \"Inpatient\",\n        \"op\",\n        \"Lu et al. 2021\",\n    ]\n\n    df_np_rodriguez = pd.read_csv(\"data/rodriguez_np_ct_mgs.csv\", sep=\";\")\n    rodriguez_patient_status_dict = {\n        \"Hospit\": \"Inpatient\",\n        \"Out_Patient\": \"Outpatient\",\n        \"Intensive_Care\": \"ICU\",\n    }\n    df_np_rodriguez[\"patient_status\"] = df_np_rodriguez[\"Group\"].replace(\n        rodriguez_patient_status_dict\n    )\n    df_np_rodriguez[\"scv2_ra\"] = (\n        df_np_rodriguez[\"Reads_2019_CoV\"] / df_np_rodriguez[\"Reads_Total\"]\n    )\n    df_np_rodriguez = df_np_rodriguez[df_np_rodriguez[\"scv2_ra\"] != 0]\n    df_np_rodriguez.rename(columns={\"CoV_Ct_number\": \"scv2_ct\"}, inplace=True)\n    df_np_rodriguez[[\"swab_type\", \"Study\"]] = [\"np\", \"Rodriguez et al. 2021\"]\n\n    df_np_babiker = pd.read_csv(\"data/babiker_np_ct_mgs.tsv\", sep=\"\\t\", skiprows=1)\n    df_np_babiker.rename(\n        columns={\n            \"SARS-CoV-2 RT-PCR Ct\": \"scv2_ct\",\n            \"SARS-CoV-2 RA\": \"scv2_ra\",\n            \"Inpatient/ED vs. Outpatient\": \"patient_status\",\n        },\n        inplace=True,\n    )\n    df_np_babiker[\"scv2_ct\"] = (\n        df_np_babiker[\"scv2_ct\"].replace(\",\", \".\", regex=True).astype(float)\n    )\n    df_np_babiker[\"patient_status\"] = df_np_babiker[\"patient_status\"].apply(\n        lambda x: x if x in [\"Inpatient\", \"Outpatient\"] else \"Unknown\"\n    )\n    df_np_babiker[\"days_from_onset\"] = (\n        df_np_babiker[\"Day of Testing Relative to Symptom Onset\"]\n        .replace(\".\", \"0\")\n        .astype(int)\n        .replace(\"0\", \"NA\")\n    )\n    df_np_babiker[[\"swab_type\", \"Study\"]] = [\"np\", \"Babiker et al. 2020\"]\n\n    df_np_mostafa = pd.read_csv(\"data/2024-05-30-mostafa-raw-ra-ct.tsv\", sep=\"\\t\")\n    mostafa_severity_dict = {\n        1: \"Required\\nventilator\",\n        2: \"ICU\",\n        3: \"Inpatient\",\n        4: \"Outpatient\",\n        0: \"Unknown\",\n    }\n    df_np_mostafa.rename(\n        columns={\n            \"SARS-CoV-2 RT-PCR Ct value\": \"scv2_ct\",\n            \"CosmosID Proportion Mapped to SARS-CoV-2\": \"scv2_ra\",\n        },\n        inplace=True,\n    )\n    df_np_mostafa[\"Severity index\"] = df_np_mostafa[\"Severity index\"].replace(\"–\", 0)\n    df_np_mostafa[\"patient_status\"] = (\n        df_np_mostafa[\"Severity index\"].astype(int).replace(mostafa_severity_dict)\n    )\n    df_np_mostafa[\"days_from_onset\"] = df_np_mostafa[\"No. of days from onset\"].replace(\n        {\"–\": \"NA\", \"<7\": \"6\"}\n    )\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"COVID-19-positive\"] == True]\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"scv2_ct\"] != \"–\"]\n    df_np_mostafa[\"scv2_ct\"] = df_np_mostafa[\"scv2_ct\"].astype(float)\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"scv2_ra\"] != 0].reset_index(drop=True)\n    df_np_mostafa[\"scv2_ra\"] = df_np_mostafa[\"scv2_ra\"].astype(float)\n    df_np_mostafa[[\"swab_type\", \"Study\"]] = [\"np\", \"Mostafa et al. 2020\"]\n\n    return [df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez]\n\n\ndef get_logit_normal_samples(ras):\n    ra_values = np.array(ras)\n    logit_ra_values = logit(ra_values)\n    mean, std = np.mean(logit_ra_values), np.std(logit_ra_values)\n    norm_dist = stats.norm(loc=mean, scale=std)\n    logit_samples = norm_dist.rvs(size=100000)\n    samples = logistic(logit_samples)\n    return samples\n\n\ndef return_swab_p2ra(subset_titles, ra_lists):\n    swab_df = pd.DataFrame()\n\n    for subset, ras in zip(subset_titles, ra_lists):\n\n        samples = get_logit_normal_samples(ras)\n\n        df = simulate_p2ra_many(samples, N_SWABS, n_simulations=10000)\n\n        df[\"Subset\"] = subset\n        swab_df = pd.concat(\n            [\n                swab_df,\n                df.melt(\n                    id_vars=\"Subset\",\n                    value_vars=N_SWABS,\n                    var_name=\"Sample Size\",\n                    value_name=\"Relative Abundance\",\n                ),\n            ]\n        )\n\n    return swab_df\n\n\ndef get_composite_p2ra():\n    composite_ras = return_composite_ras()\n    composite_p2ra_df = return_swab_p2ra([\"Original Composite Data\"], [composite_ras])\n    return composite_p2ra_df\n\ndef get_adjusted_composite_p2ra():\n    ASYMPTOMATIC_SHARE = 0.35\n    asymptomatic_ras, symptomatic_ras = return_adjusted_composite_ras()\n\n    asymptomatic_p2ra_df = return_swab_p2ra(\n        [\"Adjusted\\nComposite Data\"], [asymptomatic_ras]\n    )\n    symptomatic_p2ra_df = return_swab_p2ra(\n        [\"Adjusted\\nComposite Data\"], [symptomatic_ras]\n    )\n\n    asymptomatics = asymptomatic_p2ra_df.sample(\n        frac=ASYMPTOMATIC_SHARE, random_state=42\n    )\n    symptomatics = symptomatic_p2ra_df.sample(\n        frac=1 - ASYMPTOMATIC_SHARE, random_state=42\n    )\n\n    composite_adjusted_p2ra_df = pd.concat(\n        [asymptomatics, symptomatics], ignore_index=True\n    )\n    return composite_adjusted_p2ra_df\n\n\ndef get_study_p2ra():\n    study_ras = return_study_ras()\n    study_p2ra_df = return_swab_p2ra(SWAB_STUDY_TITLES, study_ras)\n    return study_p2ra_df\n\n\ndef get_fig_2_dfs():\n    swab_df = pd.concat([study_p2ra_df, composite_p2ra_df], ignore_index=True)\n    swab_df.reset_index(drop=True, inplace=True)\n    df_rothman_ras, df_crits_christoph_ras\n\n    df_ww = pd.DataFrame(\n        {\n            \"Relative Abundance\": df_rothman_ras + df_crits_christoph_ras,\n            \"Subset\": [\"Rothman et al. 2021\"] * len(df_rothman_ras)\n            + [\"Crits-Christoph et al. 2021\"] * len(df_crits_christoph_ras),\n        }\n    )\n\n    return swab_df, df_ww\n\n\ndef get_fig_7_dfs():\n    swab_df = pd.concat(\n        [composite_p2ra_df, adjusted_composite_p2ra_df], ignore_index=True\n    )\n    swab_df.reset_index(drop=True, inplace=True)\n    df_ww = pd.DataFrame(\n        {\n            \"Relative Abundance\": df_rothman_ras + df_crits_christoph_ras,\n            \"Subset\": [\"Rothman et al. 2021\"] * len(df_rothman_ras)\n            + [\"Crits-Christoph et al. 2021\"] * len(df_crits_christoph_ras),\n        }\n    )\n\n    return swab_df, df_ww\n\n\ndef return_composite_ras():\n    ras_lists = return_study_ras()\n    composite_swab_ras = sum(ras_lists, [])\n\n    return composite_swab_ras\n\n\ndef return_adjusted_composite_ras():\n    df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez = return_studies()\n\n    composite_df = pd.concat([df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez])\n\n    composite_df = composite_df[\n        composite_df[\"patient_status\"].isin([\"Inpatient\", \"Outpatient\"])\n    ]\n    df_asymptomatic, df_symptomatic = adjust_cts(composite_df)\n\n    df_asymptomatic_mgs_df = adjust_rel_abun(df_asymptomatic)\n    df_symptomatic_mgs_df = adjust_rel_abun(df_symptomatic)\n\n    asymptomatic_ras = df_asymptomatic_mgs_df[\"adjusted_scv2_ra\"].tolist()\n    symptomatic_ras = df_symptomatic_mgs_df[\"adjusted_scv2_ra\"].tolist()\n\n    return asymptomatic_ras, symptomatic_ras\n\n\ndef adjust_cts(df):\n    ASYMPTOMATIC_ADJUSTMENT_FACTOR = 1.50\n    NP_ADJUSTMENT_FACTOR = 1.82\n    OP_ADJUSTMENT_FACTOR = -0.92\n    df[\"adjusted_scv2_ct\"] = df[\"scv2_ct\"]\n    df.loc[df[\"swab_type\"] == \"np\", \"adjusted_scv2_ct\"] += NP_ADJUSTMENT_FACTOR\n    df.loc[df[\"swab_type\"] == \"op\", \"adjusted_scv2_ct\"] += OP_ADJUSTMENT_FACTOR\n    df_symptomatic = df.copy()\n    df_asymptomatic = df.copy()\n    df_asymptomatic[\"adjusted_scv2_ct\"] += ASYMPTOMATIC_ADJUSTMENT_FACTOR\n\n    return df_asymptomatic, df_symptomatic\n\n\ndef adjust_rel_abun(df):\n    df_np_babiker, df_np_rodriguez, df_op_lu, df_np_mostafa = return_studies()\n\n    composite_df = pd.concat([df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez])\n    composite_df[\"scv2_ra_logged\"] = composite_df[\"scv2_ra\"].apply(np.log10)\n\n    slope, intercept, r_value, p_value, std_err = linregress(\n        composite_df[\"scv2_ct\"], composite_df[\"scv2_ra_logged\"]\n    )\n    df[\"adjusted_scv2_ra_logged\"] = intercept + slope * df[\"adjusted_scv2_ct\"]\n    df[\"adjusted_scv2_ra_logged_stderr\"] = np.sqrt(\n        std_err**2 + (std_err * df[\"adjusted_scv2_ct\"]) ** 2\n    )\n\n    noise = np.random.normal(loc=0, scale=df[\"adjusted_scv2_ra_logged_stderr\"])\n    df[\"adjusted_scv2_ra_logged_with_noise\"] = df[\"adjusted_scv2_ra_logged\"] + noise\n    df[\"adjusted_scv2_ra\"] = 10 ** df[\"adjusted_scv2_ra_logged_with_noise\"]\n\n    return df\n\n\ndef return_study_ras():\n    studies = return_studies()\n    ras_lists = [df[\"scv2_ra\"].dropna().tolist() for df in studies]\n    return ras_lists\n\n\ndef return_ww_p2ra():\n    df_wastewater = pd.read_csv(\"data/2024-05-07-fits.tsv\", sep=\"\\t\")\n    df_rothman_ras = df_wastewater[\n        (df_wastewater[\"study\"] == \"rothman\")\n        & (df_wastewater[\"location\"] == \"Overall\")\n        & (df_wastewater[\"pathogen\"] == \"sars_cov_2\")\n    ][\"ra_at_1in100\"].tolist()\n    df_crits_christoph_ras = df_wastewater[\n        (df_wastewater[\"study\"] == \"crits_christoph\")\n        & (df_wastewater[\"location\"] == \"Overall\")\n        & (df_wastewater[\"pathogen\"] == \"sars_cov_2\")\n    ][\"ra_at_1in100\"].tolist()\n    return df_rothman_ras, df_crits_christoph_ras\n\n# Generate p2ra values one time before figures are created.\nstudies = return_studies()\ncomposite_p2ra_df = get_composite_p2ra()\nadjusted_composite_p2ra_df = get_adjusted_composite_p2ra()\nstudy_p2ra_df = get_study_p2ra()\ndf_rothman_ras, df_crits_christoph_ras = return_ww_p2ra()\n```\n:::\n\n\n### Figure 1\n\n::: {#d0d7cd98 .cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\n['Babiker et al. 2020'] 0.00020944604802700337 23.91917458075545\n['Rodriguez et al. 2021'] 0.0007017796848798247 25.608784312331768\n['Lu et al. 2021'] 0.0026954545743760336 30.659062534215675\n['Mostafa et al. 2020'] 0.000145860470857488 19.191571913124292\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![**Figure 1: Relative Abundance and qPCR CT values for Lu et al. 2021, Babiker et al. 2020, Mostafa et al. 2020, and Rodriguez et al. 2021.**](final_index_files/figure-html/cell-4-output-2.png){}\n:::\n:::\n\n\n### Figure 2\n\n::: {#7b83ccb1 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\nSubset: Lu et al. 2021, Sample Size: 50, Fraction of Zero Counts: 0.2983, Median: 3.313832586830832e-05\nSubset: Lu et al. 2021, Sample Size: 100, Fraction of Zero Counts: 0.0903, Median: 0.0002612283269034529\nSubset: Lu et al. 2021, Sample Size: 200, Fraction of Zero Counts: 0.0077, Median: 0.0007208277036944483\nSubset: Babiker et al. 2020, Sample Size: 50, Fraction of Zero Counts: 0.2977, Median: 2.4998833800303838e-06\nSubset: Babiker et al. 2020, Sample Size: 100, Fraction of Zero Counts: 0.0939, Median: 1.381892187636325e-05\nSubset: Babiker et al. 2020, Sample Size: 200, Fraction of Zero Counts: 0.0095, Median: 3.8024766107539184e-05\nSubset: Mostafa et al. 2020, Sample Size: 50, Fraction of Zero Counts: 0.3009, Median: 2.297594225708099e-06\nSubset: Mostafa et al. 2020, Sample Size: 100, Fraction of Zero Counts: 0.0915, Median: 5.7388425654572675e-06\nSubset: Mostafa et al. 2020, Sample Size: 200, Fraction of Zero Counts: 0.0092, Median: 8.68527120311903e-06\nSubset: Rodriguez et al. 2021, Sample Size: 50, Fraction of Zero Counts: 0.3091, Median: 6.456027134342966e-06\nSubset: Rodriguez et al. 2021, Sample Size: 100, Fraction of Zero Counts: 0.0927, Median: 7.460712025837013e-05\nSubset: Rodriguez et al. 2021, Sample Size: 200, Fraction of Zero Counts: 0.0073, Median: 0.0002887144733518676\nSubset: Original Composite Data, Sample Size: 50, Fraction of Zero Counts: 0.3082, Median: 5.089285943914015e-06\nSubset: Original Composite Data, Sample Size: 100, Fraction of Zero Counts: 0.093, Median: 4.2972091583214985e-05\nSubset: Original Composite Data, Sample Size: 200, Fraction of Zero Counts: 0.0079, Median: 0.0001415505352341001\nRothman et al. 2021 1.0003259852739905\nCrits-Christoph et al. 2021 1.0003259852739905\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![**Figure 2: Simulated RA(1%) for Lu et al. 2021, Babiker et al. 2020, Mostafa et al. 2020, and Rodriguez et al. 2021.**](final_index_files/figure-html/cell-5-output-2.png){}\n:::\n:::\n\n\n### Figure 3\n\n::: {#cell-np_nasal_ct_plot .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![**Figure 3: Nasal swabs vs nasopharyngeal swabs.** Data from Patriquin et al. 2022, McCulloch et al. 2020, Pere et al. 2020, Kojima et al. 2020, and Tu et al. 2020.](final_index_files/figure-html/np_nasal_ct_plot-output-1.png){#np_nasal_ct_plot}\n:::\n:::\n\n\n### Figure 4\n\n::: {#5ceb56b2 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Study  CT Difference\n0  Goodall et al. 2022       0.988793\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![**Figure 4: Nasal swabs vs Oro-pharyngeal swabs.** Data from Goodall et al. 2022.](final_index_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\n::: {#ac30f700 .cell execution_count=7}\n\n::: {.cell-output .cell-output-stdout}\n```\n25.47820319032225 E_NP\n27.561349723346574 E_Nasal\n28.69747823101438 E_Throat\n27.85388561349249 RdRp_NP\n30.491092457402626 RdRp_Nasal\n31.35818143535845 RdRp_Throat\n{'NP': 26.66604440190737, 'Nasal': 29.026221090374598, 'Throat': 30.027829833186416}\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_index_files/figure-html/cell-8-output-2.png){width=820 height=523}\n:::\n:::\n\n\n### Figure 5 Inpatient vs Outpatient\n\n::: {#cell-target-studies-patient-composition .cell execution_count=8}\n``` {.python .cell-code}\ndef return_fig_5():\n    df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez = return_studies()\n    order = [\"Outpatient\", \"Inpatient\", \"Required\\nventilator\", \"ICU\", \"Unknown\"]\n\n    lu_counts = df_op_lu[\"patient_status\"].value_counts().reindex(order)\n    babiker_counts = df_np_babiker[\"patient_status\"].value_counts().reindex(order)\n    mostafa_counts = df_np_mostafa[\"patient_status\"].value_counts().reindex(order)\n    rodriguez_counts = (\n        df_np_rodriguez[\"patient_status\"].value_counts().reindex(order).dropna()\n    )\n\n    print(lu_counts, babiker_counts, mostafa_counts, rodriguez_counts)\n\n    fig, axs = plt.subplots(\n        1, 4, figsize=(10, 4), width_ratios=[0.7, 1.5, 2.4, 4], sharey=True, dpi=800\n    )\n\n    colors = sns.color_palette(\"viridis\", 10)\n    color_dict = {\n        \"Outpatient\": colors[9],\n        \"Inpatient\": colors[3],\n        \"Required\\nventilator\": colors[5],\n        \"ICU\": colors[0],\n        \"Unknown\": colors[7],\n    }\n\n    axs[0].bar(\n        lu_counts.index, lu_counts.values, color=color_dict[\"Inpatient\"], width=0.5\n    )\n    axs[0].set_title(\"Lu et al. 2021\", fontsize=10)\n    axs[0].set_ylabel(\"Count\")\n\n    axs[1].bar(\n        babiker_counts.index,\n        babiker_counts.values,\n        color=[color_dict[x] for x in babiker_counts.index],\n        width=0.8,\n    )\n    axs[1].set_title(\"Babiker et al. 2020\", fontsize=10)\n    # axs[1].set_ylim(0, max(babiker_counts.values) + 5)\n\n    axs[3].bar(\n        mostafa_counts.index,\n        mostafa_counts.values,\n        color=[color_dict[x] for x in mostafa_counts.index],\n    )\n    axs[3].set_title(\"Mostafa et al. 2020\", fontsize=10)\n    axs[3].set_ylim(0, max(mostafa_counts.values) + 10)\n    axs[3].set_yticks(np.arange(0, max(mostafa_counts.values) + 30, 10))\n\n    axs[2].bar(\n        rodriguez_counts.index,\n        rodriguez_counts.values,\n        color=[color_dict[x] for x in rodriguez_counts.index],\n    )\n    axs[2].set_title(\"Rodriguez et al. 2021\", fontsize=10)\n    axs[2].set_ylim(0, max(rodriguez_counts.values) + 5)\n    axs[2].set_yticks(np.arange(0, max(rodriguez_counts.values) + 10, 5))\n\n    for ax in axs:\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"top\"].set_visible(False)\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n        ax.tick_params(\n            axis=\"x\",\n            which=\"both\",\n            top=False,\n            bottom=False,\n            labeltop=False,\n            labelbottom=True,\n            labelsize=9,\n        )\n        # ax.set_ylabel('')\n        for x in np.arange(0, 50, 10):\n            ax.axhline(\n                y=x, color=\"grey\", linestyle=\"--\", alpha=0.5, linewidth=0.5, zorder=-1\n            )\n\n    plt.tight_layout()\n    plt.savefig(\"fig/fig_5.png\", dpi=800)\n    plt.show()\n\n\nreturn_fig_5()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npatient_status\nOutpatient               NaN\nInpatient               16.0\nRequired\\nventilator     NaN\nICU                      NaN\nUnknown                  NaN\nName: count, dtype: float64 patient_status\nOutpatient              10.0\nInpatient               34.0\nRequired\\nventilator     NaN\nICU                      NaN\nUnknown                  NaN\nName: count, dtype: float64 patient_status\nOutpatient              16\nInpatient                3\nRequired\\nventilator     1\nICU                      1\nUnknown                  5\nName: count, dtype: int64 patient_status\nOutpatient    42.0\nInpatient     17.0\nICU           44.0\nName: count, dtype: float64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![**Figure 5: Patient composition of Lu et al. 2021, Babiker et al. 2020, Mostafa et al. 2020, and Rodriguez et al. 2021.**](final_index_files/figure-html/target-studies-patient-composition-output-2.png){#target-studies-patient-composition}\n:::\n:::\n\n\n#### compute share of outpatients.\n\n::: {#d37a86d1 .cell execution_count=9}\n``` {.python .cell-code}\n# TODO: Hide output.\ndf_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez = return_studies()\norder = [\"Outpatient\", \"Inpatient\", \"Required\\nventilator\", \"ICU\", \"Unknown\"]\n\nlu_counts = df_op_lu[\"patient_status\"].value_counts().reindex(order)\nbabiker_counts = df_np_babiker[\"patient_status\"].value_counts().reindex(order)\nmostafa_counts = df_np_mostafa[\"patient_status\"].value_counts().reindex(order)\nrodriguez_counts = (\n    df_np_rodriguez[\"patient_status\"].value_counts().reindex(order).dropna()\n)\n\ncomposite_counts = pd.DataFrame(\n    {\n        \"Lu\": lu_counts,\n        \"Babiker\": babiker_counts,\n        \"Mostafa\": mostafa_counts,\n        \"Rodriguez\": rodriguez_counts,\n    }\n)\n\ntotal_counts_across_studies = composite_counts.sum(axis=1)\nshare_outpatients_across_studies = (\n    total_counts_across_studies[\"Outpatient\"] / total_counts_across_studies.sum()\n)\n\nprint(total_counts_across_studies, total_counts_across_studies.sum())\nprint(\n    f\"Share of Outpatients across all studies: {share_outpatients_across_studies:.2%}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npatient_status\nICU                     45.0\nInpatient               70.0\nOutpatient              68.0\nRequired\\nventilator     1.0\nUnknown                  5.0\ndtype: float64 189.0\nShare of Outpatients across all studies: 35.98%\n```\n:::\n:::\n\n\n### Figure 6\n\n::: {#cell-knudtzen-days-status-ct .cell execution_count=10}\n``` {.python .cell-code}\n#TODO: Hide model output\nimport statsmodels.formula.api as smf\n\ndf_knudtzen_ct_days = pd.read_csv(\"data/knudtzen2021_ct_days.tsv\", sep=\"\\t\", skiprows=1)\ndf_knudtzen_ct_days[\"Patient Status\"] = df_knudtzen_ct_days[\"Patient Status\"].astype(\n    \"category\"\n)\ndf_knudtzen_ct_days[\"Day\"] = df_knudtzen_ct_days[\"Day\"].round()\nstatus_to_color = {\n    status: idx\n    for idx, status in enumerate(df_knudtzen_ct_days[\"Patient Status\"].unique())\n}\ncolors = sns.color_palette(\"viridis\", len(status_to_color))\n\nreg = smf.ols('CT ~ Day + Q(\"Patient Status\")', data=df_knudtzen_ct_days)\nresults = reg.fit()\nprint(results.summary())\n\nfig, ax = plt.subplots(figsize=(6, 3.5), dpi=600)\nfor status, color in zip(df_knudtzen_ct_days[\"Patient Status\"].unique(), colors):\n    subset = df_knudtzen_ct_days[df_knudtzen_ct_days[\"Patient Status\"] == status]\n    plt.scatter(\n        subset[\"Day\"],\n        subset[\"CT\"],\n        c=[color],\n        label=status,\n        edgecolors=\"w\",\n        linewidths=0.5,\n    )\n\n    line_x_values = range(int(subset[\"Day\"].min()), int(subset[\"Day\"].max()) + 1)\n    line_y_values = results.predict(\n        pd.DataFrame(\n            {\"Day\": line_x_values, \"Patient Status\": [status] * len(line_x_values)}\n        )\n    )\n\n    plt.plot(line_x_values, line_y_values, color=color, linestyle=\"--\", linewidth=2)\n\nplt.xlabel(\"Days from symptom onset\")\nplt.ylabel(\"qPCR-CT Value\")\nplt.legend(\n    title=\"\", loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False\n)\n\n\nfor val in range(0, 20, 5):\n    ax.axvline(x=val, color=\"grey\", linestyle=\"--\", linewidth=0.5, alpha=0.3, zorder=-1)\n\nfor val in range(15, 40, 5):\n    ax.axhline(y=val, color=\"grey\", linestyle=\"--\", linewidth=0.5, alpha=0.3, zorder=-1)\n\nax.set_xticks(range(0, int(df_knudtzen_ct_days[\"Day\"].max()) + 1, 5))\n\nax.spines[\"right\"].set_visible(False)\nax.spines[\"top\"].set_visible(False)\n\n\nplt.tight_layout()\nplt.savefig(\"fig/knudtzen_ct_days.png\", dpi=600)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                     CT   R-squared:                       0.112\nModel:                            OLS   Adj. R-squared:                  0.100\nMethod:                 Least Squares   F-statistic:                     9.138\nDate:                Tue, 18 Jun 2024   Prob (F-statistic):           0.000183\nTime:                        13:34:39   Log-Likelihood:                -440.50\nNo. Observations:                 148   AIC:                             887.0\nDf Residuals:                     145   BIC:                             896.0\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=====================================================================================================\n                                        coef    std err          t      P>|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------------------\nIntercept                            23.7782      1.142     20.822      0.000      21.521      26.035\nQ(\"Patient Status\")[T.Outpatient]    -0.6270      1.018     -0.616      0.539      -2.639       1.385\nDay                                   0.3703      0.128      2.887      0.004       0.117       0.624\n==============================================================================\nOmnibus:                        1.631   Durbin-Watson:                   0.343\nProb(Omnibus):                  0.442   Jarque-Bera (JB):                1.696\nSkew:                          -0.214   Prob(JB):                        0.428\nKurtosis:                       2.696   Cond. No.                         24.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![**Figure 6: Relationship between days from symptom onset and CT values.**](final_index_files/figure-html/knudtzen-days-status-ct-output-2.png){#knudtzen-days-status-ct}\n:::\n:::\n\n\n### Figure 7\n\n::: {#2732a080 .cell execution_count=11}\n``` {.python .cell-code}\ntable_data = defaultdict()\nww_medians = []\n\n\ndef return_fig_7():\n    plot_df_swab, plot_df_ww = get_fig_7_dfs()\n    for subset in plot_df_swab[\"Subset\"].unique():\n        for swab_sample_size in N_SWABS:\n            subset_df = plot_df_swab.query(\n                \"Subset == @subset and `Sample Size` == @swab_sample_size\"\n            )\n            median = subset_df[\"Relative Abundance\"].median()\n            zero_count_fraction = len((subset_df[\"Relative Abundance\"] == 0)) / len(\n                subset_df\n            )\n            print(\n                f\"Subset: {subset}, Sample Size: {swab_sample_size}, Fraction of Zero Counts: {zero_count_fraction}, Median: {median}\"\n            )\n\n    plot_df_ww[\"Relative Abundance\"] = np.log10(plot_df_ww[\"Relative Abundance\"])\n    plot_df_swab[\"Relative Abundance\"] = np.log10(plot_df_swab[\"Relative Abundance\"])\n\n    fig, axs = plt.subplots(\n        2,\n        1,\n        figsize=(8, 4),\n        dpi=600,\n        gridspec_kw={\"height_ratios\": [1.5, 1]},\n    )\n    fig.subplots_adjust(hspace=0.4)\n    colors = sns.color_palette(\"viridis\", 3)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[0],\n        hue=\"Sample Size\",\n        palette=colors,\n        data=plot_df_swab,\n        linewidth=0,\n        bw_adjust=1.5,\n        dodge=0.4,\n        cut=1,\n    )\n    swab_medians_logged = []\n    for subset in plot_df_swab[\"Subset\"].unique():\n        for swab_sample_size in N_SWABS:\n            median = np.median(\n                plot_df_swab[\n                    (plot_df_swab[\"Subset\"] == subset)\n                    & (plot_df_swab[\"Sample Size\"] == swab_sample_size)\n                ][\"Relative Abundance\"]\n            )\n            swab_medians_logged.append(median)\n\n    plot_medians(axs[0], swab_medians_logged)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[1],\n        color=\"#aedc31\",\n        data=plot_df_ww,\n        linewidth=0,\n        bw_adjust=1.5,\n        width=0.5,\n        dodge=0.4,\n    )\n    ww_medians_logged = []\n    for study in plot_df_ww[\"Subset\"].unique():\n        median = np.median(\n            plot_df_ww[(plot_df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n\n        ww_medians_logged.append(median)\n        ww_medians.append(10**median)\n    plot_medians(axs[1], ww_medians_logged)\n    # axs[0].set_title(\"a\", x=-0.31, y=0.9)\n    # axs[1].set_title(\"b\", x=-0.31, y=0.9)\n    axs[0].set_title(\n        \"a (Swabs)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"heavy\"\n    )\n    axs[1].set_title(\n        \"b (Wastewater)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"bold\"\n    )\n    for ax in axs:\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n        ax.set_ylabel(\"\")\n        if ax == axs[1]:\n            y_labels = [\n                (\n                    label.get_text().rsplit(\" \", 1)[0]\n                    + \"\\n\"\n                    + label.get_text().rsplit(\" \", 1)[1]\n                    if \" \" in label.get_text()\n                    else label.get_text()\n                )\n                for label in ax.get_yticklabels()\n            ]\n            ax.set_yticks(ax.get_yticks())\n            ax.set_yticklabels(y_labels)\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n    xmin, xmax = -10, 0\n    for x in np.arange(math.ceil(xmin), 1, 1):\n        axs[0].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n        axs[1].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n    for ax in axs:\n        ax.set_xlim(xmin, xmax)\n        current_xticks = ax.get_xticks()\n        ax.set_xticks(current_xticks)\n        ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n    legend = axs[0].legend(\n        title=\"Number of\\nswabs\",\n        loc=\"center left\",\n        bbox_to_anchor=(1, 0.5),\n        ncol=1,\n        frameon=False,\n    )\n    legend._legend_box.align = \"left\"\n    plt.tight_layout()\n    plt.savefig(\"fig/fig_7.png\", dpi=600)\n\n\nreturn_fig_7()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSubset: Original Composite Data, Sample Size: 50, Fraction of Zero Counts: 1.0, Median: 5.089285943914015e-06\nSubset: Original Composite Data, Sample Size: 100, Fraction of Zero Counts: 1.0, Median: 4.2972091583214985e-05\nSubset: Original Composite Data, Sample Size: 200, Fraction of Zero Counts: 1.0, Median: 0.0001415505352341001\nSubset: Adjusted\nComposite Data, Sample Size: 50, Fraction of Zero Counts: 1.0, Median: 4.029682756383334e-06\nSubset: Adjusted\nComposite Data, Sample Size: 100, Fraction of Zero Counts: 1.0, Median: 1.3157055947779586e-05\nSubset: Adjusted\nComposite Data, Sample Size: 200, Fraction of Zero Counts: 1.0, Median: 2.3433298628635916e-05\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/simongrimm/code/p2ra/venv/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning:\n\ndivide by zero encountered in log10\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_index_files/figure-html/cell-12-output-3.png){}\n:::\n:::\n\n\n::: {#7e7f5418 .cell execution_count=12}\n``` {.python .cell-code}\ndef create_table_3():\n    plot_df_swab, plot_df_ww = get_fig_7_dfs()\n\n    table_data = defaultdict()\n\n    for subset in plot_df_swab[\"Subset\"].unique():\n        for swab_sample_size in N_SWABS:\n            subset_df = plot_df_swab.query(\n                \"Subset == @subset and `Sample Size` == @swab_sample_size\"\n            )\n            median, iqr = subset_df[\"Relative Abundance\"].median(), subset_df[\n                \"Relative Abundance\"\n            ].quantile(0.75) - subset_df[\"Relative Abundance\"].quantile(0.25)\n            table_data[(subset, swab_sample_size)] = (median, iqr)\n\n    ww_medians = []\n\n    for study in plot_df_ww[\"Subset\"].unique():\n        median = np.median(\n            plot_df_ww[(plot_df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n        ww_medians.append(median)\n\n    avg_median = gmean(ww_medians)\n\n    columns = None\n    table_output = []\n\n    for key, (median, iqr) in table_data.items():\n        sample, swab_sample_size = key\n        sample = sample.replace(\"\\n\", \" \")\n\n        if columns is None:\n            columns = \"Sample Type\\tSample Size\\tMedian\\tIQR\\tDiff to Rothman\\tDiff to Crits-Christoph\\tDiff to Average\"\n            table_output.append(columns)\n\n        rothman_median = ww_medians[0]\n        crits_median = ww_medians[1]\n        diff_to_rothman = round((median / rothman_median) / 5) * 5\n        diff_to_crits = round((median / crits_median) / 5) * 5\n        diff_to_avg = round((median / avg_median) / 5) * 5\n        table_output.append(\n            f\"{sample}\\t{swab_sample_size}\\t{median:.2e}\\t{iqr:.2e}\\t{diff_to_rothman}\\t{diff_to_crits}\\t{diff_to_avg}\"\n        )\n\n    formatted_table = \"\\n\".join(table_output)\n    print(formatted_table)\n\n\ncreate_table_3()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSample Type\tSample Size\tMedian\tIQR\tDiff to Rothman\tDiff to Crits-Christoph\tDiff to Average\nOriginal Composite Data\t50\t5.09e-06\t1.46e-04\t70\t35\t50\nOriginal Composite Data\t100\t4.30e-05\t4.00e-04\t580\t310\t425\nOriginal Composite Data\t200\t1.42e-04\t6.45e-04\t1915\t1015\t1395\nAdjusted Composite Data\t50\t4.03e-06\t3.30e-05\t55\t30\t40\nAdjusted Composite Data\t100\t1.32e-05\t4.89e-05\t180\t95\t130\nAdjusted Composite Data\t200\t2.34e-05\t5.82e-05\t315\t170\t230\n```\n:::\n:::\n\n\n::: {#f80ddcd7 .cell execution_count=13}\n``` {.python .cell-code}\ndef return_fig_s1():\n    studies = SWAB_STUDY_TITLES\n    ra_lists = return_study_ras()\n    composite_ras = return_composite_ras()\n    studies.append(\"Composite\")\n    ra_lists.append(composite_ras)\n\n    raw_distributions = []\n    for ras in ra_lists:\n        samples = get_logit_normal_samples(ras)\n        raw_distributions.append(samples)\n\n\n    fig, ax = plt.subplots(1, 1, figsize=(7, 3), dpi=600)\n    log_distributions = [np.log10(distribution) for distribution in raw_distributions]\n    log_rel_abuns = [np.log10(ras) for ras in ra_lists]\n\n    viridis_palette = sns.color_palette(\"viridis\", n_colors=len(studies)-1)\n    composite_study_color = \"#aedc31\"\n    viridis_palette.append(composite_study_color)\n\n    sns.violinplot(data=log_distributions, ax=ax, inner=None, palette=viridis_palette, orient='h', zorder=1, linewidth=0.5, cut=0, alpha=1, fill=False, bw_adjust=1.5)\n\n    sns.stripplot(data=log_rel_abuns, ax=ax, jitter=True, palette=viridis_palette, orient='h', alpha=0.7, zorder=2)\n    ax.set_yticklabels(studies)\n\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.set_ylabel(\"\")\n\n    y_labels = [\n        (\n            label.get_text().rsplit(\" \", 1)[0]\n            + \"\\n\"\n            + label.get_text().rsplit(\" \", 1)[1]\n            if \" \" in label.get_text()\n            else label.get_text()\n        )\n        for label in ax.get_yticklabels()\n    ]\n    ax.set_yticklabels(y_labels)\n\n    ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n\n    current_xticks = ax.get_xticks()\n    ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n    xmin, xmax = ax.get_xlim()\n    for x in np.arange(math.ceil(xmin), 1, 1):\n        ax.axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n    ax.set_xlabel(\"Relative Abundance\")\n\n    plt.tight_layout()\n    plt.savefig(\"fig/fig_s1.png\", dpi=600)\n    plt.clf()\n\nreturn_fig_s1()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/gm/txqg8t5d57z34sqfjcvpcjj00000gn/T/ipykernel_36710/188938729.py:25: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/folders/gm/txqg8t5d57z34sqfjcvpcjj00000gn/T/ipykernel_36710/188938729.py:42: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n/var/folders/gm/txqg8t5d57z34sqfjcvpcjj00000gn/T/ipykernel_36710/188938729.py:47: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 4200x1800 with 0 Axes>\n```\n:::\n:::\n\n\n::: {#182d4638 .cell execution_count=14}\n``` {.python .cell-code}\ndef create_table_s1():\n    plot_df_swab, plot_df_ww = get_fig_2_dfs()\n\n    table_data = defaultdict()\n\n    for subset in plot_df_swab[\"Subset\"].unique():\n        for swab_sample_size in N_SWABS:\n            subset_df = plot_df_swab.query(\"Subset == @subset and `Sample Size` == @swab_sample_size\")\n            median = subset_df[\"Relative Abundance\"].median()\n            iqr = subset_df[\"Relative Abundance\"].quantile(0.75) - subset_df[\"Relative Abundance\"].quantile(0.25)\n            table_data[(subset, swab_sample_size)] = (median, iqr)\n\n    ww_medians = []\n\n    for study in plot_df_ww[\"Subset\"].unique():\n        median = np.median(\n            plot_df_ww[(plot_df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n        ww_medians.append(median)\n\n    avg_median = gmean(ww_medians)\n    print(avg_median)\n\n    columns = None\n    table_output = []\n\n\n    for key, (median, iqr) in table_data.items():\n        sample, swab_sample_size = key\n        sample = sample.replace(\"\\n\", \" \")\n\n        if columns is None:\n            columns = \"Sample Type\\tSample Size\\tMedian\\tIQR\\tDiff to Rothman\\tDiff to Crits-Christoph\\tDiff to Average\"\n            table_output.append(columns)\n\n        rothman_median = ww_medians[0]\n        crits_median = ww_medians[1]\n        diff_to_rothman = round((median / rothman_median) / 5) * 5\n        diff_to_crits = round((median / crits_median) / 5) * 5\n        diff_to_avg = round((median / avg_median) / 5) * 5\n        table_output.append(f\"{sample}\\t{swab_sample_size}\\t{median:.2e}\\t{iqr:.2e}\\t{diff_to_rothman}\\t{diff_to_crits}\\t{diff_to_avg}\")\n\n    formatted_table = \"\\n\".join(table_output)\n    print(formatted_table)\n\ncreate_table_s1()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.014761246835146e-07\nSample Type\tSample Size\tMedian\tIQR\tDiff to Rothman\tDiff to Crits-Christoph\tDiff to Average\nLu et al. 2021\t50\t3.31e-05\t7.59e-04\t450\t240\t325\nLu et al. 2021\t100\t2.61e-04\t1.91e-03\t3530\t1875\t2575\nLu et al. 2021\t200\t7.21e-04\t2.37e-03\t9745\t5180\t7105\nBabiker et al. 2020\t50\t2.50e-06\t4.25e-05\t35\t20\t25\nBabiker et al. 2020\t100\t1.38e-05\t8.55e-05\t185\t100\t135\nBabiker et al. 2020\t200\t3.80e-05\t1.51e-04\t515\t275\t375\nMostafa et al. 2020\t50\t2.30e-06\t1.22e-05\t30\t15\t25\nMostafa et al. 2020\t100\t5.74e-06\t1.56e-05\t80\t40\t55\nMostafa et al. 2020\t200\t8.69e-06\t1.59e-05\t115\t60\t85\nRodriguez et al. 2021\t50\t6.46e-06\t2.29e-04\t85\t45\t65\nRodriguez et al. 2021\t100\t7.46e-05\t7.34e-04\t1010\t535\t735\nRodriguez et al. 2021\t200\t2.89e-04\t1.41e-03\t3905\t2075\t2845\nOriginal Composite Data\t50\t5.09e-06\t1.46e-04\t70\t35\t50\nOriginal Composite Data\t100\t4.30e-05\t4.00e-04\t580\t310\t425\nOriginal Composite Data\t200\t1.42e-04\t6.45e-04\t1915\t1015\t1395\n```\n:::\n:::\n\n\n",
    "supporting": [
      "final_index_files"
    ],
    "filters": [],
    "includes": {}
  }
}