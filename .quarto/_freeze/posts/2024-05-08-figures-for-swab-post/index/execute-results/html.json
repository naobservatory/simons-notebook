{
  "hash": "9b71f097e12f80233448c195c86f76e6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Investigating the sensitivity of pooled swab sampling for pathogen early detection\nsubtitle: 'When implemented at scale, sequencing swabs in non-hospital settings could offer reliable pathogen-agnostic early detection'\nauthor:\n  - Simon Grimm\n  - Will Bradshaw\ndate: '2024-06-18'\ntoc: true\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    df-print: paged\neditor: visual\n---\n\n\n\n*Acknowledgements: Thanks to Mike McLaren and Jeff Kaufman for helpful feedback on this report. Jeff Kaufman performed an [initial exploratory analysis](https://www.jefftk.com/p/sequencing-swabs) that prompted the creation of this longer report. We also thank the authors[^1] of the qPCR and metagenomics papers we analyzed for collecting this data, making it available, and taking the time to answer our questions.\n\n[^1]: Mostafa et al. 2020, Lu et al. 2021, Rodriguez et al. 2021, Patriquin et al. 2022, McCulloch et al. 2020, Pere et al. 2020, Kojima et al. 2020, Tu et al. 2020, Berenger et al. 2020, Goodall et al. 2022, Souverein et al. 2022, Knudtzen et al. 2021, Hall et al. 2022, Long et al. 2020, Lee et al. 2022, and Yang et al. 2023\n\n# Summary\n\n * Respiratory swab sampling is central to infectious disease surveillance, but most such programs focus on targeted identification of specific pathogens. At the NAO, we’re interested in how a swab-based program would perform for more agnostic detection of novel pathogens.\n * To evaluate this, we used published metagenomic sequencing data from SARS-CoV-2 patients to predict the relative abundance of a SARS-CoV-2-like novel pathogen in sequencing data from pooled respiratory swabs collected in public places.\n * Evaluating and contextualizing these datasets, we find the following:\n    * **The sensitivity of pooled swab sampling and sequencing appears superior to wastewater sampling for a SARS-CoV-2 like pathogen.** A composite of four studies gives a relative abundance of 2.6$\\times$10^5 in a sample of 200 swabs at 1% weekly incidence. This is a 255-fold improvement compared to wastewater sampling.\n    * When adjusting existing swab sampling sequencing data to more closely represent the sample obtained in a routine sampling program, swab sampling remains superior but relative abundance drops to 6.8$\\times$10^6 (65-fold increase).\n    * Put differently, assuming a collection of 200 swabs daily, with subsequent pooling and sequencing down to around 10^6 reads, an average of 7 daily reads would match a COVID-19-like virus when at 1% weekly incidence.\n    TODO: Fill in below.\n    * Performance of a swab sampling program worsens rapidly when using swab sample sizes of 75, or 50, due to a large number of no-detects[^1].\n * The NAO is now **investigating the potential value of swab sampling and sequencing in a pilot program** in the Boston area. In this program, we are collecting, pooling, and sequencing self-administered respiratory samples to search for novel pathogens.\n\n[^1]: At 75 swabs and 50 swabs respectively, X% and Y% of pools contain no SARS-CoV-2 at 1% weekly incidence. See Appendix 2 for more information.\n\n# Introduction\n\nRespiratory pathogens must pass through the pharynx, mouth, and nose during transmission and as such, are often found in high concentrations in anterior nasal, oropharyngeal, and nasopharyngeal swabs. As a result, we hypothesized that respiratory viruses show higher [relative abundance](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6459172/#:~:text=The%20most%20simple%20and%20frequently%20used%20normalization%20is%20the%20computation%20of%20relative%20abundances%20by%20dividing%20the%20raw%20abundances%20by%20the%20total%20number%20of%20counts%20per%20sample.) (the fraction of all sequencing reads assigned to that pathogen) in respiratory swab samples than in other samples we’ve looked at previously, including [wastewater](https://www.medrxiv.org/content/10.1101/2023.12.22.23300450v2) and [air samples](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4823882). High relative abundance means less sequencing depth required for detection, which decreases sequencing costs. Combined with the relatively low regulatory hurdles associated with swabbing individuals in non-clinical settings, this makes pooled swab sampling a promising approach for detecting novel respiratory pathogens.\n\nNon-clinical swab sampling programs have precedent. One such program is [CDC’s Traveler-Based Genomic Surveillance (TGS) program](https://wwwnc.cdc.gov/travel/page/travel-genomic-surveillance) which collects swabs from international travelers entering the US. CDC TGS has traditionally focused on specific pathogens, detected via [quantitative polymerase chain reaction (qPCR)](https://en.wikipedia.org/wiki/Real-time_polymerase_chain_reaction) and [amplicon sequencing](https://eurofinsgenomics.eu/en/eurofins-genomics/material-and-methods/amplicon-sequencing/). In this post, we evaluate the performance of a more pathogen-agnostic detection method novel approach: metagenomic sequencing (MGS) of respiratory swabs from the general public.\nTo do this, we use existing sequencing data from swabs to estimate the expected relative abundance of a SARS-CoV-2-like pathogen under specific epidemiological assumptions. Specifically, we model a scenario where:\n\n * A SARS-CoV-2 like-pathogen is at 1% weekly incidence, with an assumed shedding duration of 17 days[^2], and a doubling time of 3 days (wild-type COVID-19)[^3].\n * A sampling program collects swabs from the population in public places, like train stations, public parks, or sidewalks.\n * Samples enter one pool and are sequenced using untargeted metagenomic sequencing (MGS).\n\n[^2]: We assume a shedding duration of 17 days weeks, based on SARS-COV-2 viral loads [becoming very low or undetectable 2 weeks after symptom onset](https://www.nature.com/articles/s41579-022-00822-w#:~:text=RNA%20viral%20loads%20gradually%20declined%20over%20the%20course%20of%20the%20disease%20in%20the%20nasopharyngeal%20and%20throat%20swabs%2C%20reaching%20low%20or%20undetectable%20levels%202%C2%A0weeks%20after%20symptom%20onset4%2C23%2C59%2C60%20(Fig.%C2%A02).), and viral loads being detectable around 3 days before symptom onset.\n\n[^3]: 3 days approximates the doubling time of wild-type SARS-CoV-2 at the beginning of the pandemic. Altering this parameter has a large impact on the ultimate results. See Figure S2 and S3 for results when doubling time is 7 days, and 14 days.\n\n\nIn our modeling, we use data from four different studies that performed MGS of swabs from individuals infected with SARS-CoV-2. Subsequently, we make some simple adjustments to try to account for differences between the individuals in these datasets and those who would be likely to contribute samples in non-medical settings. The results suggest that a pooled swab sampling and sequencing program could be a promising approach for MGS-based early detection of SARS-CoV-2-like novel pathogens, performing around two orders of magnitude better than a wastewater-based program.\n\n# Estimating sampling sensitivity with SARS-CoV-2 sequencing data\n\n::: {#import-and-design-functions .cell execution_count=2}\n``` {.python .cell-code}\nDEFAULT_SWAB_SAMPLE_SIZES = [100, 200, 400]\nSMALL_SWAB_SAMPLE_SIZES = [50, 75]\n\nPRINT_DATA = None\n\nWW_STUDY_TITLES = [\"Rothman et al. 2021\", \"Crits-Christoph et al. 2021\"]\n\ndef get_num_and_exp(x):\n    scientific_x = f\"{x:.1e}\"\n    number, exponent = scientific_x.split(\"e\")[0], int(scientific_x.split(\"e\")[1])\n    return number, exponent\n\n\n\n\ndef logit(x):\n    return np.log(x / (1 - x))\n\n\ndef logistic(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef return_studies():\n    df_op_lu = pd.read_csv(\"data/lu_op_ct_mgs.tsv\", sep=\"\\t\", skiprows=1)\n    df_op_lu.rename(\n        columns={\"SCV-2 Relative Abundance\": \"scv2_ra\", \"Ct value\": \"scv2_ct\"},\n        inplace=True,\n    )\n    df_op_lu[[\"patient_status\", \"swab_type\", \"Study\"]] = [\n        \"Inpatient\",\n        \"op\",\n        \"Lu et al. 2021\",\n    ]\n\n    df_np_rodriguez = pd.read_csv(\"data/rodriguez_np_ct_mgs.csv\", sep=\";\")\n    rodriguez_patient_status_dict = {\n        \"Hospit\": \"Inpatient\",\n        \"Out_Patient\": \"Outpatient\",\n        \"Intensive_Care\": \"ICU\",\n    }\n    df_np_rodriguez[\"patient_status\"] = df_np_rodriguez[\"Group\"].replace(\n        rodriguez_patient_status_dict\n    )\n    df_np_rodriguez[\"scv2_ra\"] = (\n        df_np_rodriguez[\"Reads_2019_CoV\"] / df_np_rodriguez[\"Reads_Total\"]\n    )\n    df_np_rodriguez = df_np_rodriguez[df_np_rodriguez[\"scv2_ra\"] != 0].dropna()\n    df_np_rodriguez.rename(columns={\"CoV_Ct_number\": \"scv2_ct\"}, inplace=True)\n    df_np_rodriguez[[\"swab_type\", \"Study\"]] = [\"np\", \"Rodriguez et al. 2021\"]\n\n    df_np_babiker = pd.read_csv(\"data/babiker_np_ct_mgs.tsv\", sep=\"\\t\", skiprows=1)\n    df_np_babiker.rename(\n        columns={\n            \"SARS-CoV-2 RT-PCR Ct\": \"scv2_ct\",\n            \"SARS-CoV-2 RA\": \"scv2_ra\",\n            \"Inpatient/ED vs. Outpatient\": \"patient_status\",\n        },\n        inplace=True,\n    )\n    df_np_babiker[\"scv2_ct\"] = (\n        df_np_babiker[\"scv2_ct\"].replace(\",\", \".\", regex=True).astype(float)\n    )\n    df_np_babiker[\"patient_status\"] = df_np_babiker[\"patient_status\"].apply(\n        lambda x: x if x in [\"Inpatient\", \"Outpatient\"] else \"Unknown\"\n    )\n    # The data uses . to represent missing data. Set this column to integers, while at the same time mapping missing data to NA.\n    df_np_babiker[\"days_from_onset\"] = (\n        df_np_babiker[\"Day of Testing Relative to Symptom Onset\"]\n        .replace(\".\", \"-1\")\n        .astype(int)\n        .replace(-1, \"NA\")\n    )\n    df_np_babiker[[\"swab_type\", \"Study\"]] = [\"np\", \"Babiker et al. 2020\"]\n\n    df_np_mostafa = pd.read_csv(\"data/mostafa-np-ra-ct.tsv\", sep=\"\\t\")\n    mostafa_severity_dict = {\n        1: \"Required\\nventilator\",\n        2: \"ICU\",\n        3: \"Inpatient\",\n        4: \"Outpatient\",\n        0: \"Unknown\",\n    }\n    df_np_mostafa.rename(\n        columns={\n            \"SARS-CoV-2 RT-PCR Ct value\": \"scv2_ct\",\n            \"CosmosID Proportion Mapped to SARS-CoV-2\": \"scv2_ra\",\n        },\n        inplace=True,\n    )\n    df_np_mostafa[\"Severity index\"] = df_np_mostafa[\"Severity index\"].replace(\"–\", 0)\n    df_np_mostafa[\"patient_status\"] = (\n        df_np_mostafa[\"Severity index\"].astype(int).replace(mostafa_severity_dict)\n    )\n    # There is no information of why some patients only have \"<7\" as their days from onset. We set it to 3.5 (the average of 1-6 days.)\n    df_np_mostafa[\"days_from_onset\"] = df_np_mostafa[\"No. of days from onset\"].replace(\n        {\"–\": \"NA\", \"<7\": \"3.5\"}\n    )\n    # Drop samples unless we have both qPCR and MGS detection\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"COVID-19-positive\"] == True]\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"scv2_ct\"] != \"–\"]\n    df_np_mostafa[\"scv2_ct\"] = df_np_mostafa[\"scv2_ct\"].astype(float)\n    df_np_mostafa = df_np_mostafa[df_np_mostafa[\"scv2_ra\"] != 0]\n    df_np_mostafa[\"scv2_ra\"] = df_np_mostafa[\"scv2_ra\"].astype(float)\n    df_np_mostafa[[\"swab_type\", \"Study\"]] = [\"np\", \"Mostafa et al. 2020\"]\n\n    study_dfs = {\n        \"Lu et al. 2021\": df_op_lu,\n        \"Babiker et al. 2020\": df_np_babiker,\n        \"Mostafa et al. 2020\": df_np_mostafa,\n        \"Rodriguez et al. 2021\": df_np_rodriguez,\n    }\n    return study_dfs\n\n\n\ndef return_study_ras():\n    study_dfs = return_studies().values()\n    study_ras = [df[\"scv2_ra\"].tolist() for df in study_dfs]\n    return study_ras\n\ndef return_composite_ras():\n    study_ras = return_study_ras()\n    composite_swab_ras = sum(study_ras, [])\n    return composite_swab_ras\n\n\ndef return_adjusted_composite_ras():\n    study_dfs = return_studies().values()\n\n    composite_df = pd.concat(study_dfs)\n\n    composite_df = composite_df[\n        composite_df[\"patient_status\"].isin([\"Inpatient\", \"Outpatient\"])\n    ]\n    symptom_status_dfs = adjust_cts(composite_df)\n\n    df_asymptomatic = symptom_status_dfs[\"Asymptomatic\"]\n    df_symptomatic = symptom_status_dfs[\"Symptomatic\"]\n\n    df_asymptomatic_mgs_df = adjust_rel_abun(df_asymptomatic)\n    df_symptomatic_mgs_df = adjust_rel_abun(df_symptomatic)\n\n    asymptomatic_ras = df_asymptomatic_mgs_df[\"adjusted_scv2_ra\"].tolist()\n    symptomatic_ras = df_symptomatic_mgs_df[\"adjusted_scv2_ra\"].tolist()\n\n    symptom_status_ras = {\n        \"Asymptomatic\": asymptomatic_ras,\n        \"Symptomatic\": symptomatic_ras\n    }\n\n    return symptom_status_ras\n\ndef return_study_p2ra(DEFAULT_SWAB_SAMPLE_SIZES=DEFAULT_SWAB_SAMPLE_SIZES):\n    study_ras = return_study_ras()\n    study_p2ra_df = return_swab_p2ra(SWAB_STUDY_TITLES, study_ras,DEFAULT_SWAB_SAMPLE_SIZES)\n    return study_p2ra_df\n\ndef return_composite_p2ra(DEFAULT_SWAB_SAMPLE_SIZES=DEFAULT_SWAB_SAMPLE_SIZES):\n    composite_ras = return_composite_ras()\n    composite_p2ra_df = return_swab_p2ra([\"Original Composite Data\"], [composite_ras],DEFAULT_SWAB_SAMPLE_SIZES)\n    return composite_p2ra_df\n\ndef return_adjusted_composite_p2ra(DEFAULT_SWAB_SAMPLE_SIZES=DEFAULT_SWAB_SAMPLE_SIZES):\n    ASYMPTOMATIC_SHARE = 0.35\n    symptom_status_ras = return_adjusted_composite_ras()\n\n    asymptomatic_p2ra_df = return_swab_p2ra(\n        [\"Adjusted Composite Data\"], [symptom_status_ras[\"Asymptomatic\"]], DEFAULT_SWAB_SAMPLE_SIZES\n    )\n    symptomatic_p2ra_df = return_swab_p2ra(\n        [\"Adjusted Composite Data\"], [symptom_status_ras[\"Symptomatic\"]],DEFAULT_SWAB_SAMPLE_SIZES\n    )\n\n    asymptomatics = asymptomatic_p2ra_df.sample(\n        frac=ASYMPTOMATIC_SHARE, random_state=42\n    )\n    symptomatics = symptomatic_p2ra_df.sample(\n        frac=1 - ASYMPTOMATIC_SHARE, random_state=42\n    )\n\n    composite_adjusted_p2ra_df = pd.concat(\n        [asymptomatics, symptomatics], ignore_index=True\n    )\n    return composite_adjusted_p2ra_df\n\n\n\ndef adjust_cts(df):\n    # https://doi.org/10.1371/journal.pone.0270694\n    long_2020_asymptomatic_delta = 0 # \"The initial Ct values for 37 asymptomatic individuals and 37 symptomatic patients appeared similar\" https://www.nature.com/articles/s41591-020-0965-6\n    lee_2020_asymptomatic_delta = 0 # \"There were no significant differences in Ct values between asymptomatic and symptomatic (including presymptomatic) patients.\" 10.1001/jamainternmed.2020.3862\n    yang_2023_asymptomatic_delta = 0.99 # Extracted from supplement figure 4D https://doi.org/10.1016/S2666-5247(23)00139-8\n\n\n    hall_asymptomatic_ct_median = 29.9\n    hall_symptomatic_ct_median = 21.8\n    hall_asymptomatic_delta = hall_asymptomatic_ct_median - hall_symptomatic_ct_median\n    ASYMPTOMATIC_ADJUSTMENT_FACTOR = (hall_asymptomatic_delta + long_2020_asymptomatic_delta + lee_2020_asymptomatic_delta + yang_2023_asymptomatic_delta) / 4\n\n    # TODO: do calculation of these factors in the code.\n\n    NP_ADJUSTMENT_FACTOR = 1.43\n    OP_ADJUSTMENT_FACTOR = -0.92\n    df[\"adjusted_scv2_ct\"] = df[\"scv2_ct\"]\n    df.loc[df[\"swab_type\"] == \"np\", \"adjusted_scv2_ct\"] += NP_ADJUSTMENT_FACTOR\n    df.loc[df[\"swab_type\"] == \"op\", \"adjusted_scv2_ct\"] += OP_ADJUSTMENT_FACTOR\n    df_symptomatic = df.copy()\n    df_asymptomatic = df.copy()\n    df_asymptomatic[\"adjusted_scv2_ct\"] += ASYMPTOMATIC_ADJUSTMENT_FACTOR\n\n    symptom_status_dfs = {\n        \"Asymptomatic\": df_asymptomatic,\n        \"Symptomatic\": df_symptomatic\n    }\n\n    return symptom_status_dfs\n\n\ndef adjust_rel_abun(df):\n\n    study_dfs = return_studies().values()\n\n    composite_df = pd.concat(study_dfs)\n    composite_df[\"scv2_ra_logged\"] = composite_df[\"scv2_ra\"].apply(np.log10)\n\n    slope, intercept, r_value, p_value, std_err = linregress(\n        composite_df[\"scv2_ct\"], composite_df[\"scv2_ra_logged\"]\n    )\n    df[\"adjusted_scv2_ra_logged\"] = intercept + slope * df[\"adjusted_scv2_ct\"]\n    # TODO: Double check if the math below is correct.\n    df[\"adjusted_scv2_ra_logged_stderr\"] = np.sqrt(\n        std_err**2 + (std_err * df[\"adjusted_scv2_ct\"]) ** 2\n    )\n\n    noise = np.random.normal(loc=0, scale=df[\"adjusted_scv2_ra_logged_stderr\"])\n    df[\"adjusted_scv2_ra_logged_with_noise\"] = df[\"adjusted_scv2_ra_logged\"] + noise\n    df[\"adjusted_scv2_ra\"] = 10 ** df[\"adjusted_scv2_ra_logged_with_noise\"]\n\n    return df\n\n\ndef return_swab_p2ra(subset_titles, ra_lists, DEFAULT_SWAB_SAMPLE_SIZES = DEFAULT_SWAB_SAMPLE_SIZES):\n\n    df_swab = pd.DataFrame()\n    all_samples = []\n    for subset, ras in zip(subset_titles, ra_lists):\n\n        samples = return_logit_normal_samples(ras)\n        all_samples.extend(samples)\n        if PRINT_DATA:\n            print(DEFAULT_SWAB_SAMPLE_SIZES)\n        df = simulate_p2ra_many(samples, DEFAULT_SWAB_SAMPLE_SIZES, n_simulations=10000)\n        #print(subset)\n        #column_100 = df.columns[1]\n        #print(f\"Median P2RA: {df[column_100].median():.2e}\")\n#\n#\n        #print(f\"Logit result: {gmean(samples) /41:.2e}\")\n        #print(f\"Raw RA result: {gmean(ras) / 41:.2e}\")\n        df[\"Subset\"] = subset\n        df_swab = pd.concat(\n            [\n                df_swab,\n                df.melt(\n                    id_vars=\"Subset\",\n                    value_vars=DEFAULT_SWAB_SAMPLE_SIZES,\n                    var_name=\"Sample Size\",\n                    value_name=\"Relative Abundance\",\n                ),\n            ]\n        )\n\n\n    return df_swab\n\ndef return_logit_normal_samples(ras):\n    ra_values = np.array(ras)\n    logit_ra_values = logit(ra_values)\n    mean, std = np.mean(logit_ra_values), np.std(logit_ra_values)\n    norm_dist = stats.norm(loc=mean, scale=std)\n    logit_samples = norm_dist.rvs(size=100000)\n    samples = logistic(logit_samples)\n    return samples\n\ndef simulate_p2ra_many(\n    ra_lists=[0.01], sample_populations=[100], n_simulations=1000\n) -> pd.DataFrame:\n    results = defaultdict(list)\n    for sample_pop in sample_populations:\n        for _ in range(n_simulations):\n            results[sample_pop].append(simulate_p2ra(sample_pop, ra_lists))\n    for key, values in results.items():\n        results[key] = sorted(values)\n    df = pd.DataFrame(results)\n    return df\n\n\ndef simulate_p2ra(sample_pop=100, ra_lists=[0.01], shedding_duration_d=17, doubling_period=3):\n    target_incidence_w = 0.01\n    shedding_duration_d = 17\n    days_in_week = 7\n\n    doubling_period_d = 3\n    r = np.log(2) / doubling_period_d\n    growth_factor = np.exp(r)\n    # TODO: Explain this some more, this is using the sum of a geometric sequence to arrive at the incidence on the day of sampling, given that weekly incidence is 1%.\n    current_incidence_d = target_incidence_w * (1 - 1 / growth_factor) / (1 - (1 / growth_factor) ** days_in_week)\n\n    prevalence = 0\n    for day in range(shedding_duration_d):\n        prevalence += current_incidence_d\n\n        current_incidence_d /= growth_factor\n\n    n_sick = np.random.poisson(sample_pop * prevalence)\n\n    if n_sick == 0:\n        return 0\n    cumulative_ra_sick = 0\n    for _ in range(n_sick):\n        observation = np.random.choice(ra_lists)\n        cumulative_ra_sick += observation\n    individual_ra_sick = cumulative_ra_sick / n_sick\n    relative_abundance = n_sick / sample_pop * individual_ra_sick\n    return relative_abundance\n\n\n\ndef return_fig_2_dfs():\n    df_swab = pd.concat([study_p2ra_df, composite_p2ra_df], ignore_index=True)\n\n    df_ww = pd.DataFrame(\n        {\n            \"Relative Abundance\": rothman_p2ra_ras + crits_christoph_p2ra_ras,\n            \"Subset\": [\"Rothman et al. 2021\"] * len(rothman_p2ra_ras)\n            + [\"Crits-Christoph et al. 2021\"] * len(crits_christoph_p2ra_ras),\n        }\n    )\n    return df_swab, df_ww\n\n\ndef return_fig_7_dfs():\n    df_swab = pd.concat(\n        [composite_p2ra_df, adjusted_composite_p2ra_df])\n    df_swab.reset_index(drop=True, inplace=True)\n    df_ww = pd.DataFrame(\n        {\n            \"Relative Abundance\": rothman_p2ra_ras + crits_christoph_p2ra_ras,\n            \"Subset\": [\"Rothman et al. 2021\"] * len(rothman_p2ra_ras)\n            + [\"Crits-Christoph et al. 2021\"] * len(crits_christoph_p2ra_ras),\n        }\n    )\n\n    return df_swab, df_ww\n\ndef return_ww_p2ra():\n    df_wastewater = pd.read_csv(\"data/2024-05-07-fits-subset.tsv\", sep=\"\\t\") # Original fits are taken from p2ra-manuscript. Based on the v1 pipeline (https://github.com/naobservatory/mgs-pipeline). Subset to be small enough for Github with ../scripts/subset_fits_tsv.py.\n    rothman_p2ra_ras = df_wastewater[\n        (df_wastewater[\"study\"] == \"rothman\")\n        & (df_wastewater[\"location\"] == \"Overall\")\n        & (df_wastewater[\"pathogen\"] == \"sars_cov_2\")\n    ][\"ra_at_1in100\"].tolist()\n    crits_christoph_p2ra_ras = df_wastewater[\n        (df_wastewater[\"study\"] == \"crits_christoph\")\n        & (df_wastewater[\"location\"] == \"Overall\")\n        & (df_wastewater[\"pathogen\"] == \"sars_cov_2\")\n    ][\"ra_at_1in100\"].tolist()\n\n    ww_p2ra = {\n        \"Rothman et al. 2021\": rothman_p2ra_ras,\n        \"Crits-Christoph et al. 2021\": crits_christoph_p2ra_ras\n    }\n    return ww_p2ra\n\n\n\ndef plot_medians(ax, medians):\n    patches = ax.collections\n    for patch, median in zip(patches, medians):\n        for path in patch.get_paths():\n            vertices = path.vertices\n            x_mid = median\n            closest_x = min(vertices[:, 0], key=lambda x: abs(x - x_mid))\n            y_upper = max(vertices[vertices[:, 0] == closest_x, 1])\n            y_lower = min(vertices[vertices[:, 0] == closest_x, 1])\n            ax.plot([x_mid, x_mid], [y_lower, y_upper], color=\"white\", linewidth=1.5)\n\n\n# Generate p2ra values one time before figures are created.\nstudies = return_studies()\nstudy_dfs = studies.values()\nSWAB_STUDY_TITLES = studies.keys()\ncomposite_p2ra_df = return_composite_p2ra()\nadjusted_composite_p2ra_df = return_adjusted_composite_p2ra()\nstudy_p2ra_df = return_study_p2ra()\nww_p2ra_dfs = return_ww_p2ra()\nrothman_p2ra_ras = ww_p2ra_dfs[\"Rothman et al. 2021\"]\ncrits_christoph_p2ra_ras = ww_p2ra_dfs[\"Crits-Christoph et al. 2021\"]\n```\n:::\n\n\nIn clinical settings, untargeted MGS is typically only used as a last resort for [severe undiagnosed infections](https://doi.org/10.1016/j.mib.2013.05.001). Nevertheless, there are many studies showing that MGS can detect pathogens in swab samples with decent sensitivity, including for SARS-CoV-2, [influenza](https://doi.org/10.1128/jcm.00963-19), and [other](https://journals.asm.org/doi/full/10.1128/jcm.03060-15) [pathogens](https://pubmed.ncbi.nlm.nih.gov/26209388/) including RSV, rhinovirus, adenovirus, and metapneumovirus. For the purposes of this analysis, we focus on studies that performed untargeted MGS on COVID-19 patients. We only use studies that performed qPCR alongside MGS, which gives us a mapping between targeted and untargeted quantification metrics that we can use for later adjustments (see below)[^3]. We found four such studies for which sufficient data were available:\n\n[^3]: For all swab sampling studies, we only analyze samples that test both positive in qPCR and MGS measurements.\n\n\n * [Babiker et al. 2020](https://journals.asm.org/doi/10.1128/jcm.02142-20) analyzed nasopharyngeal (NP) samples from 10 outpatients and 35 inpatients who were SARS-CoV-2 qPCR-positive[^4]. Samples were collected in Atlanta (Georgia, USA); the median (IQR) time between symptom onset and sample collection was 5 (4 to 7) days.\n * [Mostafa et al. 2020](https://journals.asm.org/doi/10.1128/mbio.01969-20), sampled NP swabs from 50 patients, 26 of which tested positive for COVID-19 in both qPCR and MGS. Sampling took place at Johns Hopkins Hospital in Baltimore (Maryland, USA). Out of these 26, 17 have information on days between symptom onset and sampling, with a mean of 5.3 days.\n * [Lu et al. 2021](https://www.nature.com/articles/s41421-021-00248-3) analyzed oropharyngeal (OP) swab samples from inpatients in Wuhan (China). The paper provides limited information on patient disease severity or other characteristics, stating only that \"Respiratory specimens (swabs) [were] collected from patients admitted to various Wuhan health care facilities.\" There is no information on the time between symptom onset and the sampling date.\n * [Rodriguez et al. 2021](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1009416) collected NP swabs from 42 outpatients, 17 inpatients not requiring intensive care and 45 intensive care unit (ICU) patients. All patients were sampled at a hospital in Paris (France). There is no information on the time between symptom onset and the sampling date.\n\n [^4]: They also ran MGS on samples of thirty individuals who tested negative to identify the underlying pathogen.\n\n\n SARS-CoV-2 relative abundance, as reported by the authors of each study, varied widely both within and between studies (Table S1, Fig. 1); in particular, Lu and Rodriguez showed substantially higher relative abundances than Babiker and Mostafa. The greatest range of relative abundances is seen in Rodriguez, with values spanning close to 7 orders of magnitude. These differences could arise from differences in swab type, sample processing, disease severity, or other factors; crucially, each study performed its own computational analysis to arrive at SARS-CoV-2 relative abundance, which might add additional inter-study variability.\n\n::: {#cell-create-fig-1 .cell execution_count=3}\n``` {.python .cell-code}\nstudies = return_studies()\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=900)\n\nfor study_df, study_title in zip(studies.values(), studies.keys()):\n    study_df[\"study\"] = study_title\n    studies[study_title] = study_df\n\ndf_np_babiker = studies[\"Babiker et al. 2020\"]\ndf_np_rodriguez = studies[\"Rodriguez et al. 2021\"]\ndf_op_lu = studies[\"Lu et al. 2021\"]\ndf_np_mostafa = studies[\"Mostafa et al. 2020\"]\n\nif PRINT_DATA:\n    for study_df in df_np_babiker, df_np_rodriguez, df_op_lu, df_np_mostafa:\n        print(\n            study_df[\"study\"].unique(),\n            f\"Relative Abundance: {gmean(study_df['scv2_ra'])}\",\n            f\"qPCR CT: {gmean(study_df['scv2_ct'])}\",\n    )\n\ncomposite_df = pd.concat([df_op_lu, df_np_babiker, df_np_mostafa, df_np_rodriguez])\n\nviridis_palette = sns.color_palette(\"viridis\", n_colors=composite_df[\"study\"].nunique())\n\nsns.histplot(\n    ax=axs[0, 0],\n    data=composite_df,\n    x=\"scv2_ra\",\n    hue=\"study\",\n    palette=viridis_palette,\n    bins=30,\n    log_scale=True,\n    element=\"bars\",\n    linewidth=0,\n    multiple=\"stack\",\n    legend=False,\n)\n\naxs[0, 0].set_title(\"a\", x=-0.08, y=1.0, ha=\"left\", fontsize=10, fontweight=\"bold\")\naxs[0, 0].set_ylabel(\"Count\")\naxs[0, 0].set_xlabel(\"Relative Abundance\")\naxs[0, 0].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n\nsns_default = sns.color_palette(n_colors=composite_df[\"patient_status\"].nunique())\nsns.histplot(\n    ax=axs[0, 1],\n    data=composite_df,\n    x=\"scv2_ra\",\n    hue=\"patient_status\",\n    palette=sns_default,\n    bins=30,\n    log_scale=True,\n    element=\"bars\",\n    linewidth=0,\n    multiple=\"stack\",\n    legend=False,\n)\naxs[0, 1].set_title(\"b\", x=-0.08, y=1.0, ha=\"left\", fontsize=10, fontweight=\"bold\")\naxs[0, 1].set_ylabel(\"Count\")\naxs[0, 1].set_xlabel(\"Relative Abundance\")\naxs[0, 1].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n\nsns.scatterplot(\n    ax=axs[1, 0],\n    data=composite_df,\n    x=\"scv2_ra\",\n    y=\"scv2_ct\",\n    hue=\"study\",\n    style=\"study\",\n    palette=viridis_palette,\n)\naxs[1, 0].set_title(\"c\", x=-0.08, y=1.0, ha=\"left\", fontsize=10, fontweight=\"bold\")\naxs[1, 0].set_xlabel(\"Relative Abundance\")\naxs[1, 0].set_ylabel(\"qPCR cycle threshold value\")\naxs[1, 0].set_xscale(\"log\")\n\naxs[1, 0].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n\nsns.move_legend(\n    axs[1, 0],\n    \"lower center\",\n    bbox_to_anchor=(0.5, -0.44),\n    ncol=2,\n    title=None,\n    frameon=False,\n    fontsize=11,\n    markerscale=2,\n)\n\nsns.scatterplot(\n    ax=axs[1, 1],\n    data=composite_df,\n    x=\"scv2_ra\",\n    y=\"scv2_ct\",\n    hue=\"patient_status\",\n    style=\"patient_status\",\n    palette=sns_default,\n)\naxs[1, 1].set_title(\"d\", x=-0.08, y=1.0, ha=\"left\", fontsize=10, fontweight=\"bold\")\naxs[1, 1].set_xlabel(\"Relative Abundance\")\naxs[1, 1].set_ylabel(\"qPCR cycle threshold value\")\naxs[1, 1].set_xscale(\"log\")\n\naxs[1, 1].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n\nsns.move_legend(\n    axs[1, 1],\n    \"lower center\",\n    bbox_to_anchor=(0.5, -0.54),\n    ncol=2,\n    title=None,\n    frameon=False,\n    fontsize=11,\n    markerscale=1.7,\n)\n\nfor ax in axs.flat:\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\nplt.tight_layout()\n#plt.savefig(\"fig/fig_1.png\", dpi=900)\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 1:** SARS-CoV-2 qPCR CT[^5] vs SARS-CoV-2 relative abundance **(a, c)** Data across studies **(b,d)** Data across patient types.](index_files/figure-html/create-fig-1-output-1.png){#create-fig-1}\n:::\n:::\n\n\n[^5]: In qPCR, a fluorescently tagged genetic target sequence undergoes repeated amplification cycles (one cycle is ~one doubling). The fluorescent signal is measured after each amplification cycle. The cycle threshold is defined as the number of cycles required for the signal to become measurable. A low CT value thus indicates the target sequence was present in higher quantities in the initial sample, as it took fewer amplification cycles for the sequence to become detectable. Conversely, a higher Ct value suggests a lower initial concentration of the target sequence. See [here](https://genomique.iric.ca/resources/files/Understanding_qPCR_results) for additional information.\n\n\nThese data can be used to estimate the expected relative abundance observed at a particular disease incidence in the population, an analysis we [previously performed](https://www.medrxiv.org/content/10.1101/2023.12.22.23300450v2) for wastewater. To generate these estimates, we simulated swabbing individuals from the population at random, with pools of swabs sequenced collectively. SARS-CoV-2 relative abundance was calculated as the average across individuals in the pool, with the relative abundance of uninfected individuals assumed to be 0 and that of infected individuals drawn from a logit-normal distribution[^6] fitted to the data in Figure 1 (see logit distributions in Figure S1).\n\n[^6]: We used a logit-normal distribution to bound the values between 0 and 1.\n\n::: {#results-for-1st-p2ra-paragraph .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\n2.926886252595507e-06\n```\n:::\n:::\n\n\nFigure 2A displays the distribution of relative abundances from a simulation where the SARS-CoV-2 incidence is 1% per week, with swabs pooled in batches of 100, 200, or 400. For a pool size of 200 swabs, the expected median SARS-CoV-2 relative abundance ranges from 2\\.9  $\\times$ 10^--6 (Mostafa et al. 2020) to 1\\.4 $\\times$ 10^-4 (Lu et al. 2021). When combining data from all four studies, the expected median relative abundance is 2\\.3 $\\times$ 10^2\\.3. In comparison, the equivalent estimate for SARS-CoV-2 in wastewater is approximately 7\\.4$\\times$ 10^-8 in Rothman et al. (2021) and 1\\.4 $\\times$ 10^-7 in Crits-Christoph et al. (2021), which are 310  and 165  times lower, respectively, than the composite swab sampling estimate at a swab sample size of 200.\n\n::: {#cell-create-fig-2 .cell execution_count=5}\n``` {.python .cell-code}\n#| fig-cap: \"**Figure 2:** Expected relative abundance at 1% SARS-CoV-2 incidence for **(a)** pooled respiratory swabs and **(b)** wastewater sequencing (data from [Grimm et al. 2024](https://www.medrxiv.org/content/10.1101/2023.12.22.23300450v2)). Violins indicate probability density only over simulations for which relative abundance was >0%; zero-abundance results aren’t plotted but can make up a substantial fraction of results ( ~29% of 100-swab pools, ~8% for 200 swabs, and ~1% for 400 swabs). Medians (indicated by white bars) incorporate these zero-abundance results.\"\n\ndef return_fig_2():\n    df_swab, df_ww = return_fig_2_dfs()\n\n    if PRINT_DATA:\n        for subset in df_swab[\"Subset\"].unique():\n            for swab_sample_size in DEFAULT_SWAB_SAMPLE_SIZES:\n                subset_df = df_swab.query(\n                \"Subset == @subset and `Sample Size` == @swab_sample_size\"\n            )\n                median = subset_df[\"Relative Abundance\"].median()\n                zero_count_fraction = (subset_df[\"Relative Abundance\"] == 0).mean()\n                print(\n                    f\"Subset: {subset}, Sample Size: {swab_sample_size}, Fraction of Zero Counts: {zero_count_fraction}, Median: {median}\"\n                )\n\n    df_ww[\"Relative Abundance\"] = np.log10(df_ww[\"Relative Abundance\"])\n    with np.errstate(divide='ignore'):\n        df_swab[\"Relative Abundance\"] = np.log10(df_swab[\"Relative Abundance\"])\n    fig, axs = plt.subplots(\n        2, 1, figsize=(8, 6), dpi=900, gridspec_kw={\"height_ratios\": [3, 1]}\n    )\n    fig.subplots_adjust(hspace=0.4)\n    colors = sns.color_palette(\"viridis\", len(DEFAULT_SWAB_SAMPLE_SIZES))\n\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[0],\n        hue=\"Sample Size\",\n        palette=colors,\n        data=df_swab,\n        linewidth=0,\n        bw_adjust=1.5,\n        dodge=0.4,\n        cut=0.5,\n    )\n\n    swab_medians_logged = []\n\n    for subset in df_swab[\"Subset\"].unique():\n        for swab_sample_size in DEFAULT_SWAB_SAMPLE_SIZES:\n            subset_df = df_swab.query(\n                \"Subset == @subset and `Sample Size` == @swab_sample_size\"\n            )\n            median_logged = subset_df[\"Relative Abundance\"].median()\n            swab_medians_logged.append(median_logged)\n\n    plot_medians(axs[0], swab_medians_logged)\n\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[1],\n        color=\"#aedc31\",\n        data=df_ww,\n        inner=None,\n        linewidth=0,\n        bw_adjust=1.5,\n        width=0.5,\n        dodge=0.2,\n    )\n\n\n    ww_medians_logged = []\n    ww_medians = []\n    for study in df_ww[\"Subset\"].unique():\n        median = np.median(\n            df_ww[(df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n\n        ww_medians_logged.append(median)\n        ww_medians.append(10**median)\n    if PRINT_DATA:\n        print(ww_medians)\n    plot_medians(axs[1], ww_medians_logged)\n\n    axs[0].set_title(\n        \"a (Swabs)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"heavy\"\n    )\n    axs[1].set_title(\n        \"b (Wastewater)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"bold\"\n    )\n\n    for ax in axs:\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n        ax.set_ylabel(\"\")\n        ax.set_yticks(ax.get_yticks())\n        y_labels = [\n            label.get_text().rsplit(\" \", 1)[0]\n            + \"\\n\"\n            + label.get_text().rsplit(\" \", 1)[1]\n            if \" \" in label.get_text()\n            else label.get_text()\n            for label in ax.get_yticklabels()\n        ]\n        ax.set_yticklabels(y_labels)\n\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n\n    xmin, xmax = -10, 0\n    axs[0].set_xlim(xmin, xmax)\n    axs[1].set_xlim(xmin, xmax)\n\n    for x in np.arange(math.ceil(xmin), 1, 1):\n        axs[0].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n        axs[1].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n\n    current_xticks = axs[0].get_xticks()\n    for ax in axs:\n        ax.set_xticks(current_xticks)\n        ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n    legend = axs[0].legend(\n        title=\"Number of\\nswabs\",\n        loc=\"center left\",\n        bbox_to_anchor=(1, 0.5),\n        ncol=1,\n        frameon=False,\n    )\n    legend._legend_box.align = \"left\"\n\n    plt.tight_layout()\n    #plt.savefig(\"fig/fig_2.png\", dpi=900)\n    #plt.savefig(\"fig/fig_2.pdf\", dpi=900)\n\n\nreturn_fig_2()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/create-fig-2-output-1.png){#create-fig-2}\n:::\n:::\n\n\n# Adjusting for confounders\n\n*Prima facie*, the results presented in Figure 2 seem like a strong argument in favor of pooled swab sampling over wastewater sampling; much higher relative abundance at a given incidence corresponds to greater detection capability at lower sequencing costs. However, the patients being sampled in these four studies are not equivalent to the random members of the public we’d expect to sample. Three differences that are particularly relevant are:\n 1. **Swab type:** the four MGS studies all used either NP swabs (Babiker et al. 2020, Mostafa et al. 2020, and Rodriguez et al. 2021), or OP swabs (Lu et al. 2021). Conversely, we expect a public-targeted sampling problem would most likely use anterior nasal (henceforth simply “nasal”) or combined nasal/OP swabs. NP swabs, in particular, are poorly suited to mass sampling, as they are quite uncomfortable and require a trained professional to perform (and are thus unsuited to self-swabbing).\n 2. **Disease severity:** Most patients in the four MGS studies were hospitalized, but a public-targeted sampling program would primarily sample from individuals who were asymptomatic, pre-symptomatic, or only mildly ill.\n 3. **Disease onset:** Most of the inpatients in the four MGS studies were sampled later in the course of their infection, but viral loads for SARS-CoV-2 (and many other diseases) are highest around symptom onset and decline over time. In public-facing sampling, we’d expect to sample infected people closer to the start of their infection than in hospitals.\nIn the rest of this section, we’ll go through each of these differences in detail and try to estimate the likely effect on the measured relative abundance at a given disease incidence.\n\n## Swab type\n\n[Tsang et al. 2021](https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(21)00402-3/fulltext) performed a meta-analysis to evaluate how well different swab types detect SARS-CoV-2 using qPCR. Swab types included nasal swabs (n=1622), OP swabs (n=388), and pooled nasal and throat swabs (n=719), each of which were compared with NP swabs[^7]. Using this approach, pooled nasal/throat swabs have the best diagnostic performance with a sensitivity of 0.97 (0.93-1.00) [8], while nasal swabs performed worse at 0.87 (0.80–0.93)\n\n[^7]: In comparing the performance of different sample types (e.g., NP swab vs nasal swab), any positive sample was treated as ground truth (there is thus no possibility of having false positives).\n\n::: {#cell-swab-type-table .cell tbl-cap='Comparison of different swab sample types. Adapted from Tsang et al. 2021' execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\n-------------------------------------------------  ----------------  ----------------\nNasal swabs (n=1622)                               0.87 (0.80–0.93)  0.95 (0.88–0.99)\nThroat swabs (n=388)                               0.75 (0.52–0.92)  0.96 (0.94–0.98)\nPooled nasal/throat swabs (n=719)                  0.97 (0.93–1.00)  0.99 (0.98–1.00)\nNP swab (n=7973, includes comparison with saliva)  0.94 (0.91–0.97)  0.99 (0.98–1.00)\n-------------------------------------------------  ----------------  ----------------\n```\n:::\n\n::: {#swab-type-table .cell-output .cell-output-display .cell-output-markdown execution_count=12}\nSample Type                                        Sensitivity       Negative Predictive Value\n-------------------------------------------------  ----------------  ---------------------------\nNasal swabs (n=1622)                               0.87 (0.80–0.93)  0.95 (0.88–0.99)\nThroat swabs (n=388)                               0.75 (0.52–0.92)  0.96 (0.94–0.98)\nPooled nasal/throat swabs (n=719)                  0.97 (0.93–1.00)  0.99 (0.98–1.00)\nNP swab (n=7973, includes comparison with saliva)  0.94 (0.91–0.97)  0.99 (0.98–1.00)\n:::\n:::\n\n\nThis study gives us binary information about a pathogen's presence in different swab types. However, to quantify the difference between swab types, we need quantitative information about the average viral load of SARS-CoV-2 in each swab type. One way to quantify this difference is by calculating the difference in cycle threshold (CT) values obtained when running qPCR on paired swabs sampled from the same person, with a lower CT indicating a higher viral load.\nTo compare NP to nasal swabs, we examined five studies that performed paired sampling and SARS-CoV-2 qPCR on the same patients using both swab types: Patriquin et al. 2022, McCulloch et al. 2020, Pere et al. 2020, Kojima et al. 2020, and Tu et al. 2020 (Fig. 3). The mean difference in CT values (NP – nasal) for the five studies were -3.05, -1.55, 0.97, -3.91 and 0.38, respectively. **The unweighted average of these five values is -1.43, indicating that NP swabs are typically more sensitive than nasal swabs.**\n\n::: {#cell-create-fig-3 .cell execution_count=7}\n``` {.python .cell-code}\ndef return_fig_3():\n    df = pd.read_csv(\"data/2024-06-18-np-nasal-ct.tsv\", sep=\"\\t\", skiprows=1)\n\n    df = df.melt(var_name=\"Study\", value_name=\"CT Difference\")\n\n    pretty_study_names = {\n        \"Patriquin2022\": \"Patriquin et al. 2022\",\n        \"McCulloch2020\": \"McCulloch et al. 2020\",\n        \"Pere2020\": \"Pere et al. 2020\",\n        \"Kojima2020\": \"Kojima et al. 2020\",\n        \"Tu2020\": \"Tu et al. 2020\",\n    }\n\n    df[\"Study\"] = df[\"Study\"].map(pretty_study_names).values\n\n    mean_ct_diff = df.groupby(\"Study\", as_index=False)[\"CT Difference\"].mean()\n    if PRINT_DATA:\n        print(mean_ct_diff)\n        print(f\"Mean CT Difference: {mean_ct_diff['CT Difference'].mean()}\")\n    fig = plt.figure(figsize=(8, 4), dpi=900)\n\n    colors = sns.color_palette(\"viridis\", len(df[\"Study\"].unique()))\n\n    sns.stripplot(\n        data=df,\n        y=\"Study\",\n        x=\"CT Difference\",\n        hue=\"Study\",\n        jitter=True,\n        zorder=-1,\n        palette=colors,\n        alpha=0.5,\n    )\n    sns.pointplot(\n        data=mean_ct_diff,\n        y=\"Study\",\n        x=\"CT Difference\",\n        linestyles=\"none\",\n        markers=\"d\",\n        color=\"#36454F\",\n        markersize=7,\n        errorbar=None,\n        zorder=1,\n    )\n    plt.legend([], [], frameon=False)\n    plt.ylabel(\"\")\n    plt.xlabel(\"SARS-CoV-2 qPCR CT Δ (NP - Nasal)\")\n    plt.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n\n    x_min, x_max = plt.xlim()\n\n    plt.text(x_max / 2, -0.6, \"Favors Nasal\", fontsize=10, color=\"black\", ha=\"center\")\n    plt.text(\n        x_min / 2, -0.6, \"Favors Nasopharyngeal\", fontsize=10, color=\"black\", ha=\"center\"\n    )\n    x_min = math.ceil(x_min / 5) * 5\n    x_max = math.ceil(x_max / 5) * 5\n\n    x_marks = np.arange(x_min, x_max, 2.5)\n    for x in x_marks:\n        if x == 0:\n            continue\n        plt.axvline(x=x, color=\"grey\", linestyle=\"--\", alpha=0.5, linewidth=0.5, zorder=-2)\n\n    plt.axvline(x=0, color=\"red\", linestyle=\"--\", alpha=0.5, zorder=-2)\n\n    plt.gca().spines[\"right\"].set_visible(False)\n    plt.gca().spines[\"top\"].set_visible(False)\n    plt.gca().spines[\"left\"].set_visible(False)\n    plt.tight_layout()\n\n    #plt.savefig(\"fig/fig_3.png\", dpi=900)\n\n\n\nreturn_fig_3()\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 3:** Nasal swabs vs NP swabs. Data from Patriquin et al. 2022, McCulloch et al. 2020, Pere et al. 2020, Kojima et al. 2020, and Tu et al. 2020. Patriquin et al. 2022 and Pere et al. 2020 performed professional collection of both NP and nasal swabs; other studies performed professional collection of NP swabs but had patients collect nasal swabs themselves.](index_files/figure-html/create-fig-3-output-1.png){#create-fig-3}\n:::\n:::\n\n\nSimilarly, to compare OP to nasal swabs, we examined two comparative studies: Berenger et al. 2020 and Goodall et al. 2022 (Fig. 4). Berenger et al. 2020 only give median, 10th, and 90th percentile values; assuming for the sake of tractability that these are drawn from a normal distribution, we get a difference between OP and nasal swabs of 0.89 (OP = 29.94, Nasal = 29.05). For Goodall, the mean difference is 0.94 (Fig. 4). **This yields an unweighted average of 0.92, indicating that OP swabs are less sensitive than nasal swabs.**\n\n::: {#cell-create-fig-4 .cell execution_count=8}\n``` {.python .cell-code}\ndef return_fig_4():\n    df = pd.read_csv(\"data/goodall-op-nasal-ct.tsv\", sep=\"\\t\", skiprows=1)\n    pretty_study_names = {\n        \"Goodall2022\": \"Goodall et al. 2022\",\n    }\n    df = df.melt(var_name=\"Study\", value_name=\"CT Difference\")\n    df[\"Study\"] = df[\"Study\"].map(pretty_study_names).values\n    mean_ct_diff = df.groupby(\"Study\", as_index=False)[\"CT Difference\"].mean()\n    if PRINT_DATA:\n        print(mean_ct_diff)\n        print(f\"Mean CT Difference: {mean_ct_diff}\")\n    fig, ax = plt.subplots(figsize=(8, 1.65), dpi=900)\n\n    viridis = sns.color_palette(\"viridis\", 1)\n    sns.stripplot(\n        data=df,\n        y=\"Study\",\n        x=\"CT Difference\",\n        hue=\"Study\",\n        jitter=True,\n        zorder=-1,\n        ax=ax,\n        alpha=0.8,\n        palette=viridis,\n    )\n    sns.pointplot(\n        data=mean_ct_diff,\n        y=\"Study\",\n        x=\"CT Difference\",\n        linestyles=\"none\",\n        markers=\"d\",\n        color=\"#36454F\",\n        markersize=8,\n        errorbar=None,\n        zorder=1,\n        ax=ax,\n    )\n    ax.legend([], [], frameon=False)\n\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"SARS-CoV-2 qPCR CT Δ (OP - Nasal)\")\n    ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n    x_min, x_max = ax.get_xlim()\n\n    ax.text(x_max / 2, -0.6, \"Favors Nasal\", fontsize=9, color=\"black\", ha=\"center\")\n    ax.text(\n        x_min / 2, -0.6, \"Favors Oropharyngeal\", fontsize=9, color=\"black\", ha=\"center\"\n    )\n\n    x_min = math.ceil(x_min / 5) * 5\n    x_max = math.ceil(x_max / 5) * 5\n\n    x_marks = np.arange(x_min, x_max, 2.5)\n    for x in x_marks:\n        if x == 0:\n            continue\n        ax.axvline(\n            x=x, color=\"grey\", linestyle=\"--\", alpha=0.5, linewidth=0.5, zorder=-2\n        )\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", alpha=0.5, zorder=-2)\n\n    ax.axhline(y=0.5, color=\"grey\", linestyle=\"--\", alpha=0.5, linewidth=0.5)\n\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    plt.tight_layout()\n    #plt.savefig(\"fig/fig_4.png\", dpi=900)\n    plt.show()\n\nreturn_fig_4()\n\n# Computing median of Berenger et al. 2020:\n\n\n# Source: https://www.medrxiv.org/content/10.1101/2020.05.05.20084889v1.full#:~:text=Comparing%20the%20samples,respectively%20(p%3E0.09).\ndata = {\n    \"E_NP\": {\"median\": 25.5, \"10th\": 20.5, \"90th\": 29.5},\n    \"E_Nasal\": {\"median\": 27.6, \"10th\": 24.7, \"90th\": 32.4},\n    \"E_Throat\": {\"median\": 28.7, \"10th\": 23.5, \"90th\": 34.2},\n    \"RdRp_NP\": {\"median\": 27.9, \"10th\": 23.5, \"90th\": 32.4},\n    \"RdRp_Nasal\": {\"median\": 30.5, \"10th\": 27.5, \"90th\": 35.0},\n    \"RdRp_Throat\": {\"median\": 31.3, \"10th\": 26.5, \"90th\": 35.5},\n}\n\n\ndef calculate_mean_std(median, p10, p90):\n    mean = median\n    std = (p90 - p10) / (2 * norm.ppf(0.9))\n    norm_dist = norm(mean, std)\n    arrived_p10 = norm_dist.ppf(0.1)\n    arrived_p90 = norm_dist.ppf(0.9)\n    if abs(p10 - arrived_p10) > 1 or abs(p90 - arrived_p90) > 1:\n        print(f\"Warning: p10 or p90 values are not within one point of the arrived percentiles. p10: {p10}, arrived_p10: {arrived_p10}, p90: {p90}, arrived_p90: {arrived_p90}\")\n    return mean, std\n\n\nx = np.linspace(10, 40, 1000)\n\ndistributions = []\n\nfor key, values in data.items():\n    mean, std = calculate_mean_std(values[\"median\"], values[\"10th\"], values[\"90th\"])\n    distribution = np.random.normal(mean, std, 100000)\n\n    distributions.append(distribution)\n\nmean_of_means = {}\nswab_types = [\"NP\", \"Nasal\", \"Throat\"]\n\n# Not doing a weighted average because there are approximately the same number of samples for both qPCR targets.\nfor swab in swab_types:\n    swab_means = [\n        np.mean(distribution)\n        for key, distribution in zip(data.keys(), distributions)\n        if swab in key\n    ]\n    mean_of_means[swab] = np.mean(swab_means)\n\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 4:** Nasal swabs vs Oro-pharyngeal swabs. Data from Goodall et al. 2022.](index_files/figure-html/create-fig-4-output-1.png){#create-fig-4}\n:::\n:::\n\n\n## Patient Status and Disease Onset\nThe four MGS studies we have examined include both inpatients and outpatients, with the latter making up 68 out of 196 individuals (36%) (Fig. 4). The remaining study population consists of inpatients with either an unknown level of disease severity, or known ventilator or ICU usage.\n\n::: {#cell-create-fig-5 .cell execution_count=9}\n``` {.python .cell-code}\ndef return_fig_5():\n    studies = return_studies()\n    df_np_babiker = studies[\"Babiker et al. 2020\"]\n    df_np_rodriguez = studies[\"Rodriguez et al. 2021\"]\n    df_op_lu = studies[\"Lu et al. 2021\"]\n    df_np_mostafa = studies[\"Mostafa et al. 2020\"]\n\n    order = [\"Outpatient\", \"Inpatient\", \"Required\\nventilator\", \"ICU\", \"Unknown\"]\n\n    lu_counts = df_op_lu[\"patient_status\"].value_counts().reindex(order)\n    babiker_counts = df_np_babiker[\"patient_status\"].value_counts().reindex(order)\n    mostafa_counts = df_np_mostafa[\"patient_status\"].value_counts().reindex(order)\n    rodriguez_counts = (\n        df_np_rodriguez[\"patient_status\"].value_counts().reindex(order).dropna())\n\n    if PRINT_DATA:\n        print(lu_counts, babiker_counts, mostafa_counts, rodriguez_counts)\n\n    fig, axs = plt.subplots(\n        1, 4, figsize=(10, 4), width_ratios=[0.7, 1.5, 2.4, 4], sharey=True, dpi=800\n    )\n\n    colors = sns.color_palette(\"viridis\", 10)\n    color_dict = {\n        \"Outpatient\": colors[9],\n        \"Inpatient\": colors[3],\n        \"Required\\nventilator\": colors[5],\n        \"ICU\": colors[0],\n        \"Unknown\": colors[7],\n    }\n\n    axs[0].bar(\n        lu_counts.index, lu_counts.values, color=color_dict[\"Inpatient\"], width=0.5\n    )\n    axs[0].set_title(\"Lu et al. 2021\", fontsize=10)\n    axs[0].set_ylabel(\"Count\")\n\n    axs[1].bar(\n        babiker_counts.index,\n        babiker_counts.values,\n        color=[color_dict[x] for x in babiker_counts.index],\n        width=0.8,\n    )\n    axs[1].set_title(\"Babiker et al. 2020\", fontsize=10)\n\n    axs[3].bar(\n        mostafa_counts.index,\n        mostafa_counts.values,\n        color=[color_dict[x] for x in mostafa_counts.index],\n    )\n    axs[3].set_title(\"Mostafa et al. 2020\", fontsize=10)\n    axs[3].set_ylim(0, max(mostafa_counts.values) + 10)\n    axs[3].set_yticks(np.arange(0, max(mostafa_counts.values) + 30, 10))\n\n    axs[2].bar(\n        rodriguez_counts.index,\n        rodriguez_counts.values,\n        color=[color_dict[x] for x in rodriguez_counts.index],\n    )\n    axs[2].set_title(\"Rodriguez et al. 2021\", fontsize=10)\n    axs[2].set_ylim(0, max(rodriguez_counts.values) + 5)\n    axs[2].set_yticks(np.arange(0, max(rodriguez_counts.values) + 10, 5))\n\n    for ax in axs:\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"top\"].set_visible(False)\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n        ax.tick_params(\n            axis=\"x\",\n            which=\"both\",\n            top=False,\n            bottom=False,\n            labeltop=False,\n            labelbottom=True,\n            labelsize=9,\n        )\n        for x in np.arange(0, 50, 10):\n            ax.axhline(\n                y=x, color=\"grey\", linestyle=\"--\", alpha=0.5, linewidth=0.5, zorder=-1\n            )\n\n    plt.tight_layout()\n    #plt.savefig(\"fig/fig_5.png\", dpi=800)\n    plt.show()\n\n\nreturn_fig_5()\n\n## Computing share of outpatients across studies\n\nstudies = return_studies()\ndf_np_babiker = studies[\"Babiker et al. 2020\"]\ndf_np_rodriguez = studies[\"Rodriguez et al. 2021\"]\ndf_op_lu = studies[\"Lu et al. 2021\"]\ndf_np_mostafa = studies[\"Mostafa et al. 2020\"]\n\norder = [\"Outpatient\", \"Inpatient\", \"Required\\nventilator\", \"ICU\", \"Unknown\"]\n\nlu_counts = df_op_lu[\"patient_status\"].value_counts().reindex(order)\nbabiker_counts = df_np_babiker[\"patient_status\"].value_counts().reindex(order)\nmostafa_counts = df_np_mostafa[\"patient_status\"].value_counts().reindex(order)\nrodriguez_counts = (\n    df_np_rodriguez[\"patient_status\"].value_counts().reindex(order).dropna()\n)\n\ncomposite_counts = pd.DataFrame(\n    {\n        \"Lu\": lu_counts,\n        \"Babiker\": babiker_counts,\n        \"Mostafa\": mostafa_counts,\n        \"Rodriguez\": rodriguez_counts,\n    }\n)\n\ntotal_counts_across_studies = composite_counts.sum(axis=1)\nshare_outpatients_across_studies = (\n    total_counts_across_studies[\"Outpatient\"] / total_counts_across_studies.sum()\n)\n\nif PRINT_DATA:\n    print(\n        f\"Share of Outpatients across all studies: {share_outpatients_across_studies:.2%}\"\n    )\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 5:** Patient composition of Lu et al. 2021, Babiker et al. 2020, Mostafa et al. 2020, and Rodriguez et al. 2021.](index_files/figure-html/create-fig-5-output-1.png){#create-fig-5}\n:::\n:::\n\n\n[Greater COVID-19 disease severity is associated with increased viral load](https://doi.org/10.1038/s41467-020-19057-5); all else equal, we thus expect hospitalized patients to show higher viral abundance than outpatients. However, [viral loads are also inversely correlated with time since symptom onset](https://www.nature.com/articles/s41579-022-00822-w).As it takes time for someone to become hospitalized, inpatients are generally tested later in the course of their disease than outpatients, resulting in lower viral loads. It’s not ex ante obvious which of these two effects we expect to dominate.\n\nPerhaps unsurprisingly, given these opposing effects, different studies give inconsistent results when comparing SARS-CoV-2 viral loads between different groups of patients. Compared to inpatients, outpatients showed higher SARS-CoV-2 CT values in Babiker et al. (mean outpatient-inpatient difference of +1.17) but lower CT values in Rodriguez et al. (mean difference of -4.45). We identified two further studies that allowed us to make this comparison: [Souverein et al. 2022](https://academic.oup.com/ofid/article/9/7/ofac223/6576478#:~:text=26.3%20(IQR%2C%205.7).-,Association%20Between%20Cp%20Value%20and%20Hospital%20Admission,-Of%20the%2020) compared ~20,000 outpatients to ~300 inpatients and found an average CT difference of +1.3, while [Knudtzen et al. 2021](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0258421#:~:text=SARS%2DCoV%2D2%20PCR%20Cq%2Dvalue%20as%20a%20marker%20for%20hospital%20admission) compared 87 outpatients to 82 inpatients and found an average difference of -2.3. An unweighted average of the CT deltas in these four studies finds that outpatients have a mean CT value 1.07 lower than inpatients; however, it’s unclear that this is a useful exercise, given the large differences between studies and confounding effect of disease onset.\n\nOne of the four studies used above, [Knudtzen et al. 2021](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0258421#:~:text=SARS%2DCoV%2D2%20PCR%20Cq%2Dvalue%20as%20a%20marker%20for%20hospital%20admission), contains information on both patient status and symptom onset, allowing us to disentangle the two effects for this dataset (Fig. 6). Fitting a simple linear model on this data, which takes into account patient status, the CT value increase per additional day is 0.37 (+- 0.13), while inpatient/outpatient status has no significant effect.\n\n::: {#cell-create-fig-6 .cell execution_count=10}\n``` {.python .cell-code}\ndef return_fig_6():\n    df_knudtzen_ct_days = pd.read_csv(\"data/knudtzen2021_ct_days.tsv\", sep=\"\\t\", skiprows=1)\n    df_knudtzen_ct_days[\"Patient Status\"] = df_knudtzen_ct_days[\"Patient Status\"].astype(\n        \"category\"\n    )\n    df_knudtzen_ct_days[\"Day\"] = df_knudtzen_ct_days[\"Day\"].round()\n    status_to_color = {\n        status: idx\n        for idx, status in enumerate(df_knudtzen_ct_days[\"Patient Status\"].unique())\n    }\n    colors = sns.color_palette(\"viridis\", len(status_to_color))\n\n    reg = smf.ols('CT ~ Day + Q(\"Patient Status\")', data=df_knudtzen_ct_days)\n    results = reg.fit()\n    if PRINT_DATA:\n        print(results.summary())\n\n    fig, ax = plt.subplots(figsize=(6, 3.5), dpi=900)\n    for status, color in zip(df_knudtzen_ct_days[\"Patient Status\"].unique(), colors):\n        subset = df_knudtzen_ct_days[df_knudtzen_ct_days[\"Patient Status\"] == status]\n        plt.scatter(\n            subset[\"Day\"],\n            subset[\"CT\"],\n            c=[color],\n            label=status,\n            edgecolors=\"w\",\n            linewidths=0.5,\n        )\n\n        line_x_values = range(int(subset[\"Day\"].min()), int(subset[\"Day\"].max()) + 1)\n        line_y_values = results.predict(\n            pd.DataFrame(\n                {\"Day\": line_x_values, \"Patient Status\": [status] * len(line_x_values)}\n            )\n        )\n\n        plt.plot(line_x_values, line_y_values, color=color, linestyle=\"--\", linewidth=2)\n\n    plt.xlabel(\"Days from symptom onset\")\n    plt.ylabel(\"qPCR-CT Value\")\n    plt.legend(\n        title=\"\", loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False\n    )\n\n\n    for val in range(0, 20, 5):\n        ax.axvline(x=val, color=\"grey\", linestyle=\"--\", linewidth=0.5, alpha=0.3, zorder=-1)\n\n    for val in range(15, 40, 5):\n        ax.axhline(y=val, color=\"grey\", linestyle=\"--\", linewidth=0.5, alpha=0.3, zorder=-1)\n\n    ax.set_xticks(range(0, int(df_knudtzen_ct_days[\"Day\"].max()) + 1, 5))\n\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n\n\n    plt.tight_layout()\n    #plt.savefig(\"fig/knudtzen_ct_days.png\", dpi=900)\n    plt.show()\n\nreturn_fig_6()\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 6:** Relationship between days since symptom onset and viral load. Data extracted from [Knudtzen et al. 2021, Figure 3A.](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0258421)](index_files/figure-html/create-fig-6-output-1.png){#create-fig-6}\n:::\n:::\n\n\nA second relevant study is He et al. 2020, who collected 414 OP swabs sampled from 94 inpatients in Guangzhou, China, none of whom were critically ill. Samples were collected longitudinally for some of these patients, with time from symptom onset ranging from 0 to 32 days. Average CT values upon symptom onset were around 31 CT values, rising to 35 at 3-4 days and reaching the limit of detection (CT=40) after 21 days. Treating the change in CT units as linear, this gives an average increase of 0.43 CT units per day; similar to the result from Knudtzen et al. Integrating the results from both of these studies, we estimate that each passing day between symptom onset and swab sampling leads to an increase of roughly 0.4 CT units.\n\n## Asymptomatic individuals\n\n\nFinally, most individuals sampled in the four MGS studies were symptomatic patients, but we expect most infected people who would be captured by a community swabbing program to be asymptomatic, presymptomatic, or only mildly ill. About one third of COVID-19 cases are persistently asymptomatic [(Sah et al. 2021)](https://paperpile.com/c/Z6Sc6W/gfVj); as such, it’s important to account for how they differ from symptomatic cases.\n\nTo investigate this, we analyzed three studies that compared qPCR results of asymptomatic COVID cases to those that were either symptomatic at the time of testing or developed symptoms later:\n\n * [Hall et al. 2022](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0270694) analyzed the results of Boston University’s testing program, which tested all individuals who came to campus, and logged symptoms upon taking the test. Comparing the median of asymptomatic individuals (n=319) with that of symptomatic (n=512) shows asymptomatics to have a CT that is 8.1 points higher (29.9 - 21.8)\n * [Long et al. 2020](https://www.nature.com/articles/s41591-020-0965-6), taking place in Wanzhou District, China, compared the first positive SARS-CoV-2 qPCR result of 37 quarantined, persistently asymptomatic individuals to 37 symptomatic patients with similar characteristics (sex, age, and comorbidities) and found no clear difference in median CT values between the two groups.\n * [Lee et al. 2022](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2769235) studied patients in a South Korean isolation facility. They do not provide raw data or median values, but report there was no qPCR CT value difference between symptomatic  (n=214) and asymptomatic patients (n=89).\n * [Yang et al. 2023](https://www.thelancet.com/journals/lanmic/article/PIIS2666-5247(23)00139-8/fulltext#sec1) performed a prospective cohort study of patients admitted to a Shenzhen hospital with lab-confirmed SARS-CoV-2 infection, collecting both symptom status and repeat qPCR measurements. They provide peak CT values for asymptomatic (n=290), mildly ill patients (n=1319), and more severely ill patients (n=434). Asymptomatic patients have a median CT value 0.99 points higher than that of mildly ill patients (the study contains vaccinated individuals which is an important confounder for symptom status and viral load).\n\n\nIt’s unclear what accounts for the large inconsistency between studies. For the purposes of this analysis, we calculated the unweighted average CT value across the four studies (2.27 CT units lower for asymptomatics compared to those who were or later became symptomatic) but this is at best a crude measure.\n\n\n# Modeling the sensitivity of a pooled swab sampling program\n\nGiven our findings above, we decided to make the following adjustments to our estimates of swab-MGS sensitivity for a SARS-CoV-2-like pathogen:\n\n1. Drop samples from ICU patients and patients on ventilators, who might differ systematically from the mildly-ill or asymptomatic cases captured by community swabbing.\n2. Adjust CT values to account for differences in swab type between the four MGS studies (NP or OP swabs) and community swabbing (nasal or combined nasal/OP swabs).\n3. Adjust CT values to account for a significant proportion of asymptomatic cases with lower viral loads.\n\nThe studies sampled many inpatients later in their disease course when viral loads were lower compared to symptom onset. Though public sampling programs would potentially sample closer to symptom onset when viral loads are higher, Lu et al. 2021 and Rodriguez et al. 2021 have limited or no data on the time between symptom onset and sampling data. Therefore, we do not adjust for this confounder.\n\nWe therefore re-estimate the expected SARS-CoV-2 relative abundance at 1% weekly incidence in the following way:\n\n 1. We create a composite dataset by combining samples from all studies.\n 2. We apply a linear regression fitted to the original qPCR and log-scale relative-abundance data, generating a relationship between qPCR and sequencing results.\n 3. We create a new composite dataset by combining samples from all studies, dropping samples from ICU patients, and individuals on ventilators, and those with unknown status.\n 4. We adjust CT values to represent nasal swabs by applying a +1.43 CT adjustment to NP swab samples and a -0.92 CT adjustment to OP samples.\n 5. We create separate asymptomatic and symptomatic versions of the dataset, applying a further +1.5 CT to the former while leaving the latter unchanged.\n 6. Separately for the asymptomatic and symptomatic distributions, we convert the adjusted CT values into adjusted SARS-CoV-2 relative abundances using the linear regression from step 2. We then fit a logit-normal distribution on the adjusted RAs as above.\n 7. We conduct Monte Carlo simulations of pooled swab samples, in which the overall relative abundance of the pool is the average of each swab, and the relative abundance of each swab is calculated as one of three states:\n    1. Non-infected: relative abundance (RA) = 0.\n    2. Infected, asymptomatic: RA drawn from adjusted RA distribution for asymptomatic cases.\n    3. Infected, symptomatic: RA drawn from adjusted RA distribution for symptomatic cases.\n\nThe results are visualized in Figure 7 and summarized in Table 3. Comparing the 200 swab sample size results to the wastewater data, swab samples are 90-fold more sensitive than Rothman et al. 2021 (7.4 $\\times$ 10^-8) and 50-fold more sensitive than Crits-Christoph et al. 2021 (1.4 $\\times$ 10^-7). **Averaging across the two wastewater studies, this gives an overall prediction of an an 65-fold difference in relative abundance between municipal wastewater and community swabbing for SARS-CoV-2**.\n\n::: {#cell-create-fig-7 .cell execution_count=11}\n``` {.python .cell-code}\ndef return_fig_7():\n    # TODO: insert line break for original comp data label.\n    df_swab, df_ww = return_fig_7_dfs()\n\n    with np.errstate(divide=\"ignore\"):\n        df_ww[\"Relative Abundance\"] = np.log10(df_ww[\"Relative Abundance\"])\n        df_swab[\"Relative Abundance\"] = np.log10(df_swab[\"Relative Abundance\"])\n\n\n    fig, axs = plt.subplots(\n        2,\n        1,\n        figsize=(8, 4),\n        dpi=900,\n        gridspec_kw={\"height_ratios\": [1.5, 1]},\n    )\n    fig.subplots_adjust(hspace=0.4)\n    colors = sns.color_palette(\"viridis\", 3)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[0],\n        hue=\"Sample Size\",\n        palette=colors,\n        data=df_swab,\n        linewidth=0,\n        bw_adjust=1.5,\n        dodge=0.4,\n        cut=1,\n    )\n    swab_medians_logged = []\n    for subset in df_swab[\"Subset\"].unique():\n        for swab_sample_size in DEFAULT_SWAB_SAMPLE_SIZES:\n            median = np.median(\n                df_swab[\n                    (df_swab[\"Subset\"] == subset)\n                    & (df_swab[\"Sample Size\"] == swab_sample_size)\n                ][\"Relative Abundance\"]\n            )\n            swab_medians_logged.append(median)\n\n    plot_medians(axs[0], swab_medians_logged)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[1],\n        color=\"#aedc31\",\n        data=df_ww,\n        linewidth=0,\n        bw_adjust=1.5,\n        width=0.5,\n        dodge=0.4,\n    )\n    ww_medians_logged = []\n    ww_medians = []\n    for study in df_ww[\"Subset\"].unique():\n        median = np.median(\n            df_ww[(df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n\n        ww_medians_logged.append(median)\n        ww_medians.append(10**median)\n    plot_medians(axs[1], ww_medians_logged)\n\n    axs[0].set_title(\n        \"a (Swabs)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"heavy\"\n    )\n    axs[1].set_title(\n        \"b (Wastewater)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"bold\"\n    )\n    for ax in axs:\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n        ax.set_ylabel(\"\")\n        if ax == axs[1]:\n            y_labels = [\n                (\n                    label.get_text().rsplit(\" \", 1)[0]\n                    + \"\\n\"\n                    + label.get_text().rsplit(\" \", 1)[1]\n                    if \" \" in label.get_text()\n                    else label.get_text()\n                )\n                for label in ax.get_yticklabels()\n            ]\n            ax.set_yticks(ax.get_yticks())\n            ax.set_yticklabels(y_labels)\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n    xmin, xmax = -10, 0\n    for x in np.arange(math.ceil(xmin), 1, 1):\n        axs[0].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n        axs[1].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n    for ax in axs:\n        ax.set_xlim(xmin, xmax)\n        current_xticks = ax.get_xticks()\n        ax.set_xticks(current_xticks)\n        ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n    legend = axs[0].legend(\n        title=\"Number of\\nswabs\",\n        loc=\"center left\",\n        bbox_to_anchor=(1, 0.5),\n        ncol=1,\n        frameon=False,\n    )\n    legend._legend_box.align = \"left\"\n    plt.tight_layout()\n    #plt.savefig(\"fig/fig_7.png\", dpi=900)\n\n\nreturn_fig_7()\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure 7:** Data adjusted to 35% asymptomatic individuals, sampled with nasal swabs. Data of ICU and ventilated patients is dropped in the adjusted dataset.](index_files/figure-html/create-fig-7-output-1.png){#create-fig-7}\n:::\n:::\n\n\n::: {#cell-p2ra-results-table .cell tbl-cap='Comparison of swab sampling relative abundance to wastewater relative abundance at 1% weekly incidence.' execution_count=12}\n\n::: {#p2ra-results-table .cell-output .cell-output-display .cell-output-markdown execution_count=18}\nSample Type                Sample Size    Median      IQR    Fold difference vs Rothman    Fold difference vs Crits-Christoph    Fold difference vs Average\n-----------------------  -------------  --------  -------  ----------------------------  ------------------------------------  ----------------------------\nOriginal Composite Data            100   3.1e-06  7.6e-05                            40                                    20                            30\nOriginal Composite Data            200   2.3e-05  0.0002                            310                                   165                           225\nOriginal Composite Data            400   7.7e-05  0.00035                          1040                                   550                           760\nAdjusted Composite Data            100   2.4e-06  1.9e-05                            35                                    15                            25\nAdjusted Composite Data            200   7.4e-06  2.7e-05                           100                                    55                            75\nAdjusted Composite Data            400   1.3e-05  3.1e-05                           180                                    95                           130\n:::\n:::\n\n\n# Estimating the cost\n\nGiven the estimates of relative abundance calculated above, we can in turn compare the sequencing costs required to detect a novel SARS-CoV-2-like pathogen spreading in the population to those required for wastewater-based detection.\nUsing our estimate of relative abundance at 1% weekly incidence for 200-swab pools, we can estimate the weekly sequencing depth V required for detection at 1% cumulative incidence like so[^8]:\n\n[^8]: This approach is discussed further in our [previous preprint on wastewater](https://www.medrxiv.org/content/10.1101/2023.12.22.23300450v2.full.pdf?#page=17.59).\n\n::: {#cost-estimate .cell execution_count=13}\n\n::: {.cell-output .cell-output-stdout}\n```\n2.4093483399578753e-06\n```\n:::\n:::\n\n\nTODO: FIX equation\n\n$V = \\frac{\\text{detection threshold}}{100} \\times RA(1%) \\times \\text{cumulative incidence}$\n\nTODO: Double check daily sequencing number.\n\nAssuming a detection threshold of 100 cumulative reads, this yields a weekly sequencing depth of 4\\.2 $\\times$ 10^7 per week, or around 8\\.3  $\\times$ 10^6million reads per day.  This is approximately equal to one MinION sequencing run per day, with consumable costs of around $450.  Scaling up to a whole year gives a variable cost of sequencing of roughly $Xk per year. In comparison, our equivalent estimate for wastewater-based detection comes to several million dollars USD per year.\n\nBased on this estimate, we expect the ultimate cost of a community-based swab-sampling program to be dominated by costs other than those directly associated with sequencing, including participant compensation, sample processing, and computational analysis.\n\n# Conclusion\n\nIn this post, we evaluate the expected sensitivity of pooled swab sampling and untargeted metagenomic sequencing for detecting a SARS-CoV-2-like pathogen. By analyzing MGS data from COVID-19 studies and adjusting for swab type and symptom status, we estimated the relative abundance of SARS-CoV-2 reads that could be obtained at a 1% weekly incidence. Our results suggest that this approach may offer roughly two orders of magnitude greater sensitivity compared to municipal wastewater.\n\nThis investigation has several obvious limitations. Most glaringly, we only used data on SARS-CoV-2, making extrapolation to other diseases (let alone hypothetical future ones) difficult. The adjustments made to account for confounding factors in the second half of the post are fairly simplistic, and we aren’t confident that the results would stand up to a more rigorous (and time-consuming) analysis. Even having made these adjustments, our estimate of the relative abundance that could be achieved with swab sampling spans many orders of magnitude, leaving us with a high degree of uncertainty about the true efficacy of swab sampling for MGS-based detection of COVID-like pathogens.\n\nNevertheless, we do believe that these results provide reason to be optimistic about the performance of pooled swab sampling for metagenomic biosurveillance, especially compared to municipal wastewater. Averaging across the two wastewater studies considered here gives a fold-difference in relative abundance (at 1% weekly COVID-19 incidence) of X for the raw estimate and X after adjusting for confounders. This increase in relative abundance brings a concomitant decrease in the sequencing depth required for detection, substantially reducing the cost of such a program compared to wastewater-based detection.\n\nThese results suggest that swab sampling in non-hospital settings could be a comparatively cheap and sensitive way to detect novel pathogens. CDC’s TGS program (see above) demonstrates the logistical feasibility of large-scale swab sampling, collecting samples from almost 50,000 individuals in just over a year. Incorporating metagenomic sequencing into such a program would help identify and mitigate the spread of novel biological threats.\n\n\n# Appendix\n\n## Appendix 1: Logit-normal distributions\n\n::: {#cell-fig_s1 .cell execution_count=14}\n``` {.python .cell-code}\ndef return_fig_s1():\n    study_labels = list(return_studies().keys())\n    ra_lists = return_study_ras()\n    composite_ras = return_composite_ras()\n    study_labels.append(\"Composite Data\")\n    ra_lists.append(composite_ras)\n    raw_distributions = []\n    for ras in ra_lists:\n        samples = return_logit_normal_samples(ras)\n        raw_distributions.append(samples)\n\n\n    fig, ax = plt.subplots(1, 1, figsize=(7, 3), dpi=900)\n    log_distributions = [np.log10(distribution) for distribution in raw_distributions]\n    log_rel_abuns = [np.log10(ras) for ras in ra_lists]\n\n    viridis_palette = sns.color_palette(\"viridis\", n_colors=len(study_labels)-1)\n    composite_study_color = \"#aedc31\"\n    viridis_palette.append(composite_study_color)\n\n    sns.violinplot(data=log_distributions, ax=ax, inner=None, palette=viridis_palette, orient='h', zorder=1, linewidth=0.5, cut=0, alpha=1, fill=False, bw_adjust=1.5)\n\n    sns.stripplot(data=log_rel_abuns, ax=ax, jitter=True, palette=viridis_palette, orient='h', alpha=0.7, zorder=2)\n    ax.set_yticks(ax.get_yticks())\n    ax.set_yticklabels(study_labels)\n\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.set_ylabel(\"\")\n\n    y_labels = [\n        (\n            label.get_text().rsplit(\" \", 1)[0]\n            + \"\\n\"\n            + label.get_text().rsplit(\" \", 1)[1]\n            if \" \" in label.get_text()\n            else label.get_text()\n        )\n        for label in ax.get_yticklabels()\n    ]\n\n    ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n    #x_min, x_max = ax.get_xlim()\n    new_x_max = 0\n    new_x_min = -10\n    ax.set_xlim(new_x_min, new_x_max)\n    current_xticks = ax.get_xticks()\n\n\n    ax.set_xticks(current_xticks)\n    ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n\n    for x in np.arange(math.ceil(new_x_min), 1, 1):\n        ax.axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n    ax.set_xlabel(\"Relative Abundance\")\n\n    plt.tight_layout()\n    plt.show()\n\n\nreturn_fig_s1()\n```\n\n::: {.cell-output .cell-output-display}\n![**Figure S1:** Raw relative abundance values and logit-normal distributions for each study.](index_files/figure-html/fig_s1-output-1.png){#fig_s1}\n:::\n:::\n\n\n## Appendix 2: Swab sample performance when sampling 50 and 75 swabs\n\n::: {#417efbe6 .cell execution_count=15}\n``` {.python .cell-code}\ndef return_fig_s2_dfs():\n\n    composite_p2ra_df = return_composite_p2ra(DEFAULT_SWAB_SAMPLE_SIZES=SMALL_SWAB_SAMPLE_SIZES)\n    adjusted_composite_p2ra_df = return_adjusted_composite_p2ra(DEFAULT_SWAB_SAMPLE_SIZES=SMALL_SWAB_SAMPLE_SIZES)\n    df_swab = pd.concat(\n        [composite_p2ra_df, adjusted_composite_p2ra_df])\n    df_swab.reset_index(drop=True, inplace=True)\n    df_ww = pd.DataFrame(\n        {\n            \"Relative Abundance\": rothman_p2ra_ras + crits_christoph_p2ra_ras,\n            \"Subset\": [\"Rothman et al. 2021\"] * len(rothman_p2ra_ras)\n            + [\"Crits-Christoph et al. 2021\"] * len(crits_christoph_p2ra_ras),\n        }\n    )\n\n    return df_swab, df_ww\n\ndef return_fig_s2():\n    df_swab, df_ww = return_fig_s2_dfs()\n\n    with np.errstate(divide=\"ignore\"):\n        df_ww[\"Relative Abundance\"] = np.log10(df_ww[\"Relative Abundance\"])\n        df_swab[\"Relative Abundance\"] = np.log10(df_swab[\"Relative Abundance\"])\n\n\n    fig, axs = plt.subplots(\n        2,\n        1,\n        figsize=(8, 4),\n        dpi=900,\n        gridspec_kw={\"height_ratios\": [1.5, 1]},\n    )\n    fig.subplots_adjust(hspace=0.4)\n    colors = sns.color_palette(\"viridis\", 2)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[0],\n        hue=\"Sample Size\",\n        palette=colors,\n        data=df_swab,\n        linewidth=0,\n        bw_adjust=1.5,\n        dodge=0.4,\n        cut=1,\n    )\n    swab_medians_logged = []\n    for subset in df_swab[\"Subset\"].unique():\n        for swab_sample_size in SMALL_SWAB_SAMPLE_SIZES:\n            median = np.median(\n                df_swab[\n                    (df_swab[\"Subset\"] == subset)\n                    & (df_swab[\"Sample Size\"] == swab_sample_size)\n                ][\"Relative Abundance\"]\n            )\n            swab_medians_logged.append(median)\n\n    plot_medians(axs[0], swab_medians_logged)\n    sns.violinplot(\n        x=\"Relative Abundance\",\n        y=\"Subset\",\n        ax=axs[1],\n        color=\"#aedc31\",\n        data=df_ww,\n        linewidth=0,\n        bw_adjust=1.5,\n        width=0.5,\n        dodge=0.4,\n    )\n    ww_medians_logged = []\n    ww_medians = []\n    for study in df_ww[\"Subset\"].unique():\n        median = np.median(\n            df_ww[(df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n        )\n\n        ww_medians_logged.append(median)\n        ww_medians.append(10**median)\n    plot_medians(axs[1], ww_medians_logged)\n\n    axs[0].set_title(\n        \"a (Swabs)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"heavy\"\n    )\n    axs[1].set_title(\n        \"b (Wastewater)\", x=-0.31, y=0.95, fontsize=10, ha=\"left\", fontweight=\"bold\"\n    )\n    for ax in axs:\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n        ax.set_ylabel(\"\")\n        if ax == axs[1]:\n            y_labels = [\n                (\n                    label.get_text().rsplit(\" \", 1)[0]\n                    + \"\\n\"\n                    + label.get_text().rsplit(\" \", 1)[1]\n                    if \" \" in label.get_text()\n                    else label.get_text()\n                )\n                for label in ax.get_yticklabels()\n            ]\n            ax.set_yticks(ax.get_yticks())\n            ax.set_yticklabels(y_labels)\n        ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n    xmin, xmax = -10, 0\n    for x in np.arange(math.ceil(xmin), 1, 1):\n        axs[0].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n        axs[1].axvline(\n            x=x, color=\"black\", linestyle=\"--\", linewidth=0.3, alpha=0.2, zorder=-1\n        )\n    for ax in axs:\n        ax.set_xlim(xmin, xmax)\n        current_xticks = ax.get_xticks()\n        ax.set_xticks(current_xticks)\n        ax.set_xticklabels(\n            [\n                \"$10^{{{}}}$\".format(int(value)) if value != 0 else \"1\"\n                for value in current_xticks\n            ]\n        )\n    legend = axs[0].legend(\n        title=\"Number of\\nswabs\",\n        loc=\"center left\",\n        bbox_to_anchor=(1, 0.5),\n        ncol=1,\n        frameon=False,\n    )\n    legend._legend_box.align = \"left\"\n    plt.tight_layout()\n    #plt.savefig(\"fig/fig_7.png\", dpi=900)\n\n\nreturn_fig_s2()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){}\n:::\n:::\n\n\n::: {#14f488c5 .cell tbl-cap='Comparison of swab sampling relative abundance to wastewater relative abundance at 1% weekly incidence, assuming swab sample sizes of 50 and 75.' execution_count=16}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=22}\n                           Sample Type    Sample Size    Median    IQR    Zero Count %Fold difference vs Rothman    Fold difference vs Crits-Christoph    Fold difference vs Average\n-----------------------  -------------  -------------  --------  -----  ----------------------------------------  ------------------------------------  ----------------------------\nOriginal Composite Data             50        0         1.4e-05      1                                         0                                     0                             0\nOriginal Composite Data             75        4.8e-07   4.1e-05      0                                         5                                     5                             5\nAdjusted Composite Data             50        0         8e-06        1                                         0                                     0                             0\nAdjusted Composite Data             75        7.8e-07   1.3e-05      0                                        10                                     5                            10\n:::\n:::\n\n\n## Appendix 3: Results for individual study data and unadjusted composite data when using 100, 200, and 400 swabs.\n\n::: {#b073f229 .cell tbl-cap='Comparison study-level and unadjusted composite swab sampling relative abundance to wastewater relative abundance at 1% weekly incidence.' execution_count=17}\n``` {.python .cell-code}\n#| echo: false\n\ndf_swab, df_ww = return_fig_2_dfs()\n\ntable_data = defaultdict()\n\nfor subset in df_swab[\"Subset\"].unique():\n    for swab_sample_size in DEFAULT_SWAB_SAMPLE_SIZES:\n        subset_df = df_swab.query(\"Subset == @subset and `Sample Size` == @swab_sample_size\")\n        median = subset_df[\"Relative Abundance\"].median()\n        iqr = subset_df[\"Relative Abundance\"].quantile(0.75) - subset_df[\"Relative Abundance\"].quantile(0.25)\n        table_data[(subset, swab_sample_size)] = (median, iqr)\n\nww_medians = []\n\nfor study in df_ww[\"Subset\"].unique():\n    median = np.median(\n        df_ww[(df_ww[\"Subset\"] == study)][\"Relative Abundance\"]\n    )\n    ww_medians.append(median)\n\navg_median = gmean(ww_medians)\n\n\ncolumns = None\ntable_output = []\n\n\nfor key, (median, iqr) in table_data.items():\n    sample, swab_sample_size = key\n    sample = sample.replace(\"\\n\", \" \")\n\n    #if columns is None:\n    #    columns = \"Sample Type\\tSample Size\\tMedian\\tIQR\\tFold difference vs Rothman\\tFold difference vs Crits-Christoph\\tFold difference vs Average\"\n    #    table_output.append(columns)\n\n    rothman_median = ww_medians[0]\n    crits_median = ww_medians[1]\n    fold_improvement_rothman = round((median / rothman_median) / 5) * 5\n    fold_improvement_crits = round((median / crits_median) / 5) * 5\n    diff_to_avg = round((median / avg_median) / 5) * 5\n\n    pretty_median = f\"{median:.1e}\"\n    pretty_iqr = f\"{iqr:.1e}\"\n\n    sample = sample.replace(\"\\n\", \"\")\n    table_output.append(\n        [sample, swab_sample_size, pretty_median, pretty_iqr, fold_improvement_rothman, fold_improvement_crits, diff_to_avg]\n    )\n\nprint(tabulate(table_output))\nMarkdown(\n    tabulate(\n    table_output,\n    headers=[\"Sample Type\", \"Sample Size\", \"Median\", \"IQR\", \"Fold difference vs Rothman\", \"Fold difference vs Crits-Christoph\", \"Fold difference vs Average\"]\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-----------------------  ---  -------  -------  ----  ----  ----\nLu et al. 2021           100  1.9e-05  0.00038   250   135   185\nLu et al. 2021           200  0.00014  0.00088  1850   980  1345\nLu et al. 2021           400  0.00038  0.0012   5070  2695  3695\nBabiker et al. 2020      100  1.4e-06  2.2e-05    20    10    15\nBabiker et al. 2020      200  8.2e-06  5.3e-05   110    60    80\nBabiker et al. 2020      400  2.1e-05  8.2e-05   285   150   210\nMostafa et al. 2020      100  1.2e-06  6.2e-06    15    10    10\nMostafa et al. 2020      200  2.9e-06  8e-06      40    20    30\nMostafa et al. 2020      400  4.5e-06  8.2e-06    60    30    45\nRodriguez et al. 2021    100  4.2e-06  0.00014    55    30    40\nRodriguez et al. 2021    200  3.6e-05  0.00037   490   260   360\nRodriguez et al. 2021    400  0.00014  0.00069  1880  1000  1370\nOriginal Composite Data  100  3.1e-06  7.6e-05    40    20    30\nOriginal Composite Data  200  2.3e-05  0.0002    310   165   225\nOriginal Composite Data  400  7.7e-05  0.00035  1040   550   760\n-----------------------  ---  -------  -------  ----  ----  ----\n```\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=23}\nSample Type                Sample Size    Median      IQR    Fold difference vs Rothman    Fold difference vs Crits-Christoph    Fold difference vs Average\n-----------------------  -------------  --------  -------  ----------------------------  ------------------------------------  ----------------------------\nLu et al. 2021                     100   1.9e-05  0.00038                           250                                   135                           185\nLu et al. 2021                     200   0.00014  0.00088                          1850                                   980                          1345\nLu et al. 2021                     400   0.00038  0.0012                           5070                                  2695                          3695\nBabiker et al. 2020                100   1.4e-06  2.2e-05                            20                                    10                            15\nBabiker et al. 2020                200   8.2e-06  5.3e-05                           110                                    60                            80\nBabiker et al. 2020                400   2.1e-05  8.2e-05                           285                                   150                           210\nMostafa et al. 2020                100   1.2e-06  6.2e-06                            15                                    10                            10\nMostafa et al. 2020                200   2.9e-06  8e-06                              40                                    20                            30\nMostafa et al. 2020                400   4.5e-06  8.2e-06                            60                                    30                            45\nRodriguez et al. 2021              100   4.2e-06  0.00014                            55                                    30                            40\nRodriguez et al. 2021              200   3.6e-05  0.00037                           490                                   260                           360\nRodriguez et al. 2021              400   0.00014  0.00069                          1880                                  1000                          1370\nOriginal Composite Data            100   3.1e-06  7.6e-05                            40                                    20                            30\nOriginal Composite Data            200   2.3e-05  0.0002                            310                                   165                           225\nOriginal Composite Data            400   7.7e-05  0.00035                          1040                                   550                           760\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}